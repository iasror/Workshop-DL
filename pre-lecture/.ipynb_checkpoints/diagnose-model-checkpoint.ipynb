{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to diagnose Deep Neural Networks models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** << important >> ** This crash course is originally taken from https://machinelearningmastery.com/diagnose-overfitting-underfitting-lstm-models/ with some modification. Please do not re-distribute without any acknowledgment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of this tutorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How to gather and plot training history of LSTM models.\n",
    "* How to diagnose an underfit, good fit, and overfit model.\n",
    "* How to develop more robust diagnostics by averaging multiple model runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training History in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn a lot about the behavior of your model by reviewing its performance over time.\n",
    "\n",
    "Keras models are trained by calling the fit() function. This function returns a variable called history that contains a trace of the loss and any other metrics specified during the compilation of the model. These scores are recorded at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "\n",
    "history = model.fit(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if your model was compiled to optimize the log loss (binary_crossentropy) and measure accuracy each epoch, then the log loss and accuracy will be calculated and recorded in the history trace for each training epoch. Each score is accessed by a key in the history object returned from calling fit(). By default, the loss optimized when fitting the model is called “loss” and accuracy is called “acc“."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs=100)\n",
    "print(history.history['loss'])\n",
    "print(history.history['acc'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras also allows you to specify a separate validation dataset while fitting your model that can also be evaluated using the same loss and metrics. \n",
    "\n",
    "This can be done by setting the validation_split argument on fit() to use a portion of the training data as a validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.33)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be done by setting the validation_data argument and passing a tuple of X and y datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "history = model.fit(X, Y, epochs=100, validation_data=(valX, valY))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics evaluated on the validation dataset are keyed using the same names, with a “val_” prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.33)\n",
    "print(history.history['loss'])\n",
    "print(history.history['acc'])\n",
    "print(history.history['val_loss'])\n",
    "print(history.history['val_acc'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: reading stored history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "\n",
    "HISTORY_PATH = '../practical/history'\n",
    "MODEL_PATH = '../practical/models'\n",
    "\n",
    "# saving file into pickle format\n",
    "def savePickle(dataToWrite,pickleFilename):\n",
    "    f = open(pickleFilename, 'wb')\n",
    "    cPickle.dump(dataToWrite, f)\n",
    "    f.close()\n",
    "    \n",
    "# reading file in pickle format\n",
    "def readPickle(pickleFilename):\n",
    "    f = open(pickleFilename, 'rb')\n",
    "    obj = cPickle.load(f)\n",
    "    f.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss = np.array(readPickle(os.path.join(HISTORY_PATH,'imdb_cnn_batch_loss')))\n",
    "batch_accuracy  = np.array(readPickle(os.path.join(HISTORY_PATH,'imdb_cnn_batch_accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1564,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1564,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46810108,  0.511397  ,  0.42507434,  0.52697074,  0.50562197,\n",
       "        0.36038339,  0.40839443,  0.44586515,  0.52497804,  0.46128878], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13157508,  0.26187623,  0.16067153,  0.36001459,  0.04748184,\n",
       "        0.08533902,  0.13597971,  0.34944224,  0.27516654], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78125,  0.75   ,  0.90625,  0.875  ,  0.78125,  0.90625,\n",
       "        0.9375 ,  0.8125 ,  0.75   ,  0.75   ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.875  ,  0.875  ,  0.84375,  0.96875,  0.96875,  1.     ,\n",
       "        0.875  ,  0.875  ,  0.875  ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy[:-10:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Diagnostic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training history can be used to diagnose the behavior of the model.\n",
    "\n",
    "We can plot the performance of the model using the Matplotlib library. For example, we can plot training loss vs test loss as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "from matplotlib import pyplot\n",
    "...\n",
    "history = model.fit(X, Y, epochs=100, validation_data=(valX, valY))\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our case, we will just read stored history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_loss = readPickle(os.path.join(HISTORY_PATH,'imdb_cnn_epoch_loss'))\n",
    "ep_val_loss  = readPickle(os.path.join(HISTORY_PATH,'imdb_cnn_epoch_val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJksWFsYYY7JkYWGMMSZLFhbGGGOy9P91L4XZTsaj4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4291a10518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(ep_loss)\n",
    "pyplot.plot(ep_val_loss)\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and reviewing these plots can help to inform you about possible new configurations to try in order to get better performance from your model.\n",
    "\n",
    "Next, we will look at some examples. We will consider model skill on the train and validation sets in terms of loss that is minimized. You can use any metric that is meaningful on your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The question is: what this graph means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Underfit Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An underfit model is one that is demonstrated to perform well on the training dataset and poor on the test dataset.\n",
    "\n",
    "This can be diagnosed from a plot where the training loss is lower than the validation loss, and the validation loss has a trend that suggests further improvements are possible.\n",
    "\n",
    "A small contrived example of an underfit LSTM model is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1234 - val_loss: 0.7569\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 753us/step - loss: 0.1218 - val_loss: 0.7513\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1202 - val_loss: 0.7457\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1187 - val_loss: 0.7402\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.7347\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1156 - val_loss: 0.7292\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1141 - val_loss: 0.7237\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1126 - val_loss: 0.7183\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1111 - val_loss: 0.7130\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1096 - val_loss: 0.7076\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1082 - val_loss: 0.7023\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1067 - val_loss: 0.6970\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1053 - val_loss: 0.6918\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1039 - val_loss: 0.6866\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1025 - val_loss: 0.6814\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.6763\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0997 - val_loss: 0.6712\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 0.6661\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0970 - val_loss: 0.6611\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0957 - val_loss: 0.6562\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0944 - val_loss: 0.6512\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0931 - val_loss: 0.6463\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0918 - val_loss: 0.6414\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0906 - val_loss: 0.6366\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.6318\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.6271\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.6223\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0856 - val_loss: 0.6176\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.6130\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.6084\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.6038\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.5993\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.5947\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0786 - val_loss: 0.5903\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0775 - val_loss: 0.5858\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0764 - val_loss: 0.5814\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0753 - val_loss: 0.5770\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 725us/step - loss: 0.0743 - val_loss: 0.5727\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.5683\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0721 - val_loss: 0.5640\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.5598\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.5555\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.5513\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.5471\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - val_loss: 0.5430\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.5389\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.5348\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.5307\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - val_loss: 0.5266\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - val_loss: 0.5226\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0613 - val_loss: 0.5186\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.5146\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.5107\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0586 - val_loss: 0.5067\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0577 - val_loss: 0.5028\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.4989\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0560 - val_loss: 0.4951\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0551 - val_loss: 0.4912\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0543 - val_loss: 0.4874\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0534 - val_loss: 0.4836\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.4798\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.4761\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0510 - val_loss: 0.4723\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.4686\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.4649\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.4612\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.4576\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.4539\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0464 - val_loss: 0.4503\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.4467\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.4432\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.4396\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.4361\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.4326\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0422 - val_loss: 0.4291\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.4256\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.4222\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.4187\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.4153\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.4120\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.4086\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.4053\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.4019\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - val_loss: 0.3986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0359 - val_loss: 0.3954\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0354 - val_loss: 0.3921\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.3889\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.3856\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.3825\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.3793\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.3761\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0321 - val_loss: 0.3730\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.3699\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0311 - val_loss: 0.3668\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.3638\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.3607\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.3577\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.3548\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.3518\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.3489\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=100, validation_data=(valX, valY), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example produces a plot of train and validation loss showing the characteristic of an underfit model. In this case, performance may be improved by increasing the number of training epochs.\n",
    "\n",
    "In this case, performance may be improved by increasing the number of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCgUREYlRKIiISIxCQUREYhQKIiIS8/8BOheGRS4mA74AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f42781e3b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, a model may be underfit if performance on the training set is better than the validation set and performance has leveled off. Below is an example of an\n",
    "\n",
    "Below is an example of an an underfit model with insufficient memory cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mae', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 1)                 12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2971 - val_loss: 0.7806\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2870 - val_loss: 0.7706\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2770 - val_loss: 0.7605\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2670 - val_loss: 0.7505\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2570 - val_loss: 0.7405\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2470 - val_loss: 0.7304\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2370 - val_loss: 0.7204\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2269 - val_loss: 0.7103\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2169 - val_loss: 0.7003\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2069 - val_loss: 0.6903\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1969 - val_loss: 0.6842\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1933 - val_loss: 0.6782\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1897 - val_loss: 0.6722\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1861 - val_loss: 0.6661\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1825 - val_loss: 0.6601\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.6541\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1752 - val_loss: 0.6480\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1716 - val_loss: 0.6420\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1680 - val_loss: 0.6360\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1644 - val_loss: 0.6299\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1608 - val_loss: 0.6239\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1572 - val_loss: 0.6179\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.6118\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1500 - val_loss: 0.6058\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1464 - val_loss: 0.5997\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1427 - val_loss: 0.5937\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1391 - val_loss: 0.5877\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1370 - val_loss: 0.5856\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1366 - val_loss: 0.5836\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1362 - val_loss: 0.5816\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1358 - val_loss: 0.5796\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.5775\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1350 - val_loss: 0.5755\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1346 - val_loss: 0.5735\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1342 - val_loss: 0.5715\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1338 - val_loss: 0.5694\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.5674\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1330 - val_loss: 0.5654\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 912us/step - loss: 0.1325 - val_loss: 0.5634\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1321 - val_loss: 0.5613\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1317 - val_loss: 0.5593\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1313 - val_loss: 0.5573\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1309 - val_loss: 0.5553\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.5532\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.5512\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1297 - val_loss: 0.5492\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1293 - val_loss: 0.5471\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1289 - val_loss: 0.5451\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1285 - val_loss: 0.5431\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1281 - val_loss: 0.5411\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1277 - val_loss: 0.5390\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1273 - val_loss: 0.5370\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1269 - val_loss: 0.5350\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1264 - val_loss: 0.5330\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 718us/step - loss: 0.1260 - val_loss: 0.5309\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1256 - val_loss: 0.5289\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1252 - val_loss: 0.5269\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1248 - val_loss: 0.5249\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1244 - val_loss: 0.5228\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1240 - val_loss: 0.5208\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1236 - val_loss: 0.5188\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1232 - val_loss: 0.5167\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.5147\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1224 - val_loss: 0.5127\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1220 - val_loss: 0.5107\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1216 - val_loss: 0.5086\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1212 - val_loss: 0.5066\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1208 - val_loss: 0.5046\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1203 - val_loss: 0.5026\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1199 - val_loss: 0.5005\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1195 - val_loss: 0.4985\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 0.4965\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1187 - val_loss: 0.4944\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1183 - val_loss: 0.4924\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.4904\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1182 - val_loss: 0.4924\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.4904\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1182 - val_loss: 0.4923\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1179 - val_loss: 0.4903\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.4923\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.4903\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.4923\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.4902\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.4922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.4902\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1182 - val_loss: 0.4922\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.4902\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1182 - val_loss: 0.4922\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1178 - val_loss: 0.4901\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.4921\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1178 - val_loss: 0.4901\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1182 - val_loss: 0.4921\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.4901\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.4920\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.4900\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.4920\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.4900\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1182 - val_loss: 0.4920\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1178 - val_loss: 0.4899\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.4919\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1178 - val_loss: 0.4939\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1182 - val_loss: 0.4919\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.4939\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1182 - val_loss: 0.4918\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.4938\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1182 - val_loss: 0.4918\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1178 - val_loss: 0.4938\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.4918\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.4938\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1181 - val_loss: 0.4917\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.4937\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1181 - val_loss: 0.4917\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.4937\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1181 - val_loss: 0.4917\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.4936\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.4916\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4936\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.4916\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4936\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.4915\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1177 - val_loss: 0.4935\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.4915\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4935\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.4915\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4935\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1181 - val_loss: 0.4914\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4934\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1181 - val_loss: 0.4914\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4934\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.4914\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4933\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1180 - val_loss: 0.4913\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1177 - val_loss: 0.4933\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.4913\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1177 - val_loss: 0.4933\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1180 - val_loss: 0.4912\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1177 - val_loss: 0.4932\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.4912\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1177 - val_loss: 0.4932\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1180 - val_loss: 0.4912\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4932\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1180 - val_loss: 0.4911\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4931\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1180 - val_loss: 0.4911\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4931\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1180 - val_loss: 0.4910\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4930\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1180 - val_loss: 0.4910\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4930\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.4910\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4930\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.4909\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4929\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.4909\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4929\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1179 - val_loss: 0.4909\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4928\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1179 - val_loss: 0.4908\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4928\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.4908\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1176 - val_loss: 0.4928\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.4907\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4927\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.4907\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1176 - val_loss: 0.4927\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.4907\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.4906\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4926\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.4906\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4926\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1178 - val_loss: 0.4905\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4925\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.4905\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1176 - val_loss: 0.4925\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1178 - val_loss: 0.4905\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1176 - val_loss: 0.4925\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.4904\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4924\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.4904\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1176 - val_loss: 0.4924\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1178 - val_loss: 0.4904\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4923\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.4903\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4923\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.4903\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1176 - val_loss: 0.4923\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.4902\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4922\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1178 - val_loss: 0.4902\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4922\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1177 - val_loss: 0.4902\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4922\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1177 - val_loss: 0.4901\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4921\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4901\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4921\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1177 - val_loss: 0.4900\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4920\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4900\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.4920\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4900\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1175 - val_loss: 0.4920\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1177 - val_loss: 0.4899\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4919\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4899\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1175 - val_loss: 0.4919\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1177 - val_loss: 0.4899\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.4918\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1177 - val_loss: 0.4898\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.4918\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.4898\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1175 - val_loss: 0.4918\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1176 - val_loss: 0.4897\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.4917\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4897\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1175 - val_loss: 0.4917\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4897\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1175 - val_loss: 0.4916\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4896\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4916\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4896\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1175 - val_loss: 0.4916\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4895\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.4915\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1176 - val_loss: 0.4895\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4915\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4895\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4915\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4894\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1175 - val_loss: 0.4914\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.4894\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4914\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.4893\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1175 - val_loss: 0.4913\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1175 - val_loss: 0.4893\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4913\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4893\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4913\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4892\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1175 - val_loss: 0.4912\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4892\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4912\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4892\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4911\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.4891\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4911\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1175 - val_loss: 0.4891\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4911\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1175 - val_loss: 0.4890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4910\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1175 - val_loss: 0.4890\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1174 - val_loss: 0.4910\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1174 - val_loss: 0.4890\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1174 - val_loss: 0.4909\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1174 - val_loss: 0.4889\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4909\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1174 - val_loss: 0.4889\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1174 - val_loss: 0.4909\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4888\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4908\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4888\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1174 - val_loss: 0.4908\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4888\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4907\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4887\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1174 - val_loss: 0.4907\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4887\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4907\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1174 - val_loss: 0.4886\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4906\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4886\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1174 - val_loss: 0.4906\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.4886\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4906\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1173 - val_loss: 0.4885\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4905\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4885\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.4905\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.4884\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4904\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1173 - val_loss: 0.4884\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1173 - val_loss: 0.4904\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1173 - val_loss: 0.4884\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1173 - val_loss: 0.4904\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4883\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1173 - val_loss: 0.4903\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1173 - val_loss: 0.4883\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.4903\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4882\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4902\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4882\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1173 - val_loss: 0.4902\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1172 - val_loss: 0.4882\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.4902\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1172 - val_loss: 0.4881\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4901\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1172 - val_loss: 0.4881\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.4901\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 714us/step - loss: 0.1172 - val_loss: 0.4881\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example shows the characteristic of an underfit model that appears under-provisioned.\n",
    "\n",
    "In this case, performance may be improved by increasing the capacity of the model, such as the number of memory cells in a hidden layer or number of hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERFJU1IQEZE0JQUREUlTUhARkbT/DxFTTiDIQ0u6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f427391f668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Good Fit Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good fit is a case where the performance of the model is good on both the train and validation sets.\n",
    "\n",
    "This can be diagnosed from a plot where the train and validation loss decrease and stabilize around the same point.\n",
    "\n",
    "The small example below demonstrates an LSTM model with a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.1187 - val_loss: 0.7256\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1174 - val_loss: 0.7207\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1160 - val_loss: 0.7159\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1147 - val_loss: 0.7111\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1134 - val_loss: 0.7063\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.7015\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.6967\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1095 - val_loss: 0.6920\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1082 - val_loss: 0.6873\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.6826\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1057 - val_loss: 0.6779\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1044 - val_loss: 0.6733\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1032 - val_loss: 0.6687\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1019 - val_loss: 0.6640\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1007 - val_loss: 0.6595\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0995 - val_loss: 0.6549\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.6503\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0971 - val_loss: 0.6458\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0959 - val_loss: 0.6413\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0947 - val_loss: 0.6368\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0936 - val_loss: 0.6324\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0924 - val_loss: 0.6279\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.6235\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0901 - val_loss: 0.6191\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0890 - val_loss: 0.6147\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0879 - val_loss: 0.6103\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.6060\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0857 - val_loss: 0.6016\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0846 - val_loss: 0.5973\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0835 - val_loss: 0.5930\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.5888\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0813 - val_loss: 0.5845\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.5803\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.5761\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0782 - val_loss: 0.5719\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0772 - val_loss: 0.5678\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.5636\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.5595\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.5554\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.5513\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.5472\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - val_loss: 0.5432\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.5392\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.5352\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.5312\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - val_loss: 0.5272\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.5233\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - val_loss: 0.5193\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.5154\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.5115\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - val_loss: 0.5077\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.5038\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0612 - val_loss: 0.5000\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.4962\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.4924\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.4886\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.4849\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - val_loss: 0.4811\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0561 - val_loss: 0.4774\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.4737\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.0545 - val_loss: 0.4700\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.4664\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.4627\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 769us/step - loss: 0.0522 - val_loss: 0.4591\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0514 - val_loss: 0.4555\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.4519\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.4484\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.4448\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.4413\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.4378\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0470 - val_loss: 0.4343\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0463 - val_loss: 0.4308\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.4274\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.4240\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0443 - val_loss: 0.4205\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.4171\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0430 - val_loss: 0.4138\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.4104\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.4071\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.4038\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.4005\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.3972\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0392 - val_loss: 0.3939\n",
      "Epoch 84/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.3907\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.3875\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - val_loss: 0.3843\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.3811\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.3779\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0357 - val_loss: 0.3748\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.3717\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0346 - val_loss: 0.3686\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0341 - val_loss: 0.3655\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0336 - val_loss: 0.3625\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0330 - val_loss: 0.3594\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0325 - val_loss: 0.3564\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0320 - val_loss: 0.3534\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.3504\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.3475\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0306 - val_loss: 0.3446\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.3417\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0296 - val_loss: 0.3388\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.3359\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.3331\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.3302\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.3274\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0275 - val_loss: 0.3247\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.3219\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.3192\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.3164\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.3138\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.3111\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.3084\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.3058\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.3032\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.3006\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.2981\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.2956\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.2931\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.2906\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.2881\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 864us/step - loss: 0.0221 - val_loss: 0.2857\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.2833\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.2809\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.2785\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.0209 - val_loss: 0.2762\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 843us/step - loss: 0.0206 - val_loss: 0.2738\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.2715\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.2693\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.2670\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.2648\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.2626\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.2604\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.2583\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.2561\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.2540\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.2519\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.2499\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.2479\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.2458\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.2439\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.2419\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.2400\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.2380\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.2362\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.2343\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.2324\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.2306\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.2288\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.2270\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.2253\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.2236\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.2219\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.2202\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.2185\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.2169\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.2153\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.2137\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.2121\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.2106\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.2090\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.2075\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.2061\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.2046\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.2032\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.2017\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1990\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1976\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1963\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1950\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.1937\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1924\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1912\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.1899\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.1887\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.1875\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.1863\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.1852\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.1840\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.1829\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1818\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.1807\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1796\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.1786\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1776\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.1765\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.1755\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.1746\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.1736\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1726\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.1717\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1708\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.1698\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.1690\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1681\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.1672\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.1664\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.1655\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1647\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.1639\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.1631\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.1623\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.1615\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1607\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.1600\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.1593\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.1585\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1578\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.1571\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.1564\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.1557\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1550\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.1544\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1537\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.1531\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.1524\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1518\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.1512\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1506\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1500\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1494\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1488\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.1482\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.1476\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1471\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.1465\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.1460\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.1454\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.1449\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.1444\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.1438\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1433\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1428\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1423\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.1418\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1413\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.1408\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.1403\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1398\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.1393\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.1389\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.1384\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.1379\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1375\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.1370\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.1366\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1361\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1357\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1348\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1344\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.1339\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1335\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.1331\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.1326\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.1322\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.1318\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.1314\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.1310\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.1306\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.1301\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.1297\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.1293\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.1289\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.1285\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1281\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.1277\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.1273\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.1269\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.1265\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1261\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.1257\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.1254\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.1250\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.1246\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1242\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.1238\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1234\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1230\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1227\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.1223\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1219\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.1215\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1211\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.1208\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.1204\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.1200\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.1196\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1192\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.1189\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.1185\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.1181\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1178\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.1174\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1170\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.1166\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1163\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.1159\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.1155\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.1151\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1148\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.1144\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.1140\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.1137\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.1133\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1129\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.1126\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.1122\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.1118\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1115\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.1111\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.1107\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.1103\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.1100\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.1096\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1092\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.1089\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.1085\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.1081\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1078\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.1074\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.1070\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.1067\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.1063\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.1059\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.1056\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.1052\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.1048\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.1045\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.1041\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.1038\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1030\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.1027\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.1023\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.1019\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.1016\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.1012\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.1008\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.1005\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.1001\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0997\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0994\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0990\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0986\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0983\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0979\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0976\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0972\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0968\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0965\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0961\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.0957\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.0954\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0950\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0947\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0943\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0939\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0936\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0932\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0928\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0925\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0921\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0918\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0914\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0910\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0907\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 847us/step - loss: 0.0075 - val_loss: 0.0903\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0900\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0896\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0892\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0889\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0885\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0882\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0878\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0874\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0871\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0867\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0864\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0860\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0857\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0853\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0849\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0846\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0842\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0839\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0835\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0832\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0828\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0825\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0821\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0817\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0814\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0810\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0807\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0803\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0800\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0796\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0793\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0789\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0786\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0782\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0779\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0775\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0772\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0768\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0765\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0761\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0758\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0754\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0751\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0747\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0744\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0740\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0733\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0730\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0726\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0723\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0720\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0716\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0713\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0709\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0706\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0702\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0699\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0696\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0692\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0689\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0685\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0682\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0679\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0675\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0672\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0668\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0665\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0662\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0658\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0655\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0652\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0648\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0645\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0642\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0638\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0635\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0632\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0628\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0625\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0622\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0618\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0615\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0612\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0608\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0605\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0602\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0599\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0595\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0592\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0589\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0586\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0582\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0579\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0576\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0573\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0569\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0566\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0563\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0560\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0557\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0553\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0550\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0547\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0544\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0541\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0537\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0534\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0531\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0528\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0525\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0522\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0519\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0516\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0512\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0509\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0506\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0503\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0500\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0497\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0494\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0491\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0488\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0485\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0482\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0479\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0476\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0473\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0470\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0464\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0461\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0458\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0455\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0452\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0449\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0446\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0443\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0440\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0437\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0434\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0431\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0428\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0426\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0423\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0420\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0417\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0414\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0411\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0408\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0406\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0403\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0400\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0397\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0394\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0392\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0389\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0386\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0383\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0381\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0378\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0375\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0372\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0370\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0367\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0364\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0362\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0359\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0356\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0354\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0351\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0348\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0346\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0343\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0340\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0338\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0335\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0333\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0330\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0327\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0325\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0322\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0320\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0317\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0315\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0312\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0310\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0307\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0305\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0302\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0300\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0297\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0295\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0293\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0290\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0288\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0285\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0283\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0281\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0278\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0276\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0274\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0271\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0269\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0267\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0264\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0262\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0260\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0257\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0255\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0253\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0251\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0246\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0244\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0242\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0240\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0237\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0235\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0233\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0231\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0229\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0227\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0225\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0222\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0220\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0218\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0216\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0214\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0212\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0210\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0208\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0206\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0204\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0202\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0200\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0198\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0196\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0194\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0192\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0190\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0188\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0187\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0185\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0183\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0181\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0179\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0177\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0175\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0174\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0172\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0170\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0168\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0166\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0165\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0163\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0161\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0159\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0158\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0156\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0154\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0152\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0151\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0149\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0147\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0146\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0144\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0143\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0141\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0139\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0138\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0136\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0135\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0133\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0131\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0130\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0128\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0127\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0124\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0122\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0121\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0119\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0118\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0117\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0115\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0114\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0112\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0111\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0110\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0108\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0107\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0106\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0104\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0099\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0098\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0096\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0095\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0094\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0091\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0090\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0089\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0088\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0087\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0085\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0084\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0083\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0082\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0081\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0080\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0078\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0077\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0076\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0075\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0074\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0073\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0072\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0071\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0070\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.9148e-04 - val_loss: 0.0069\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.8156e-04 - val_loss: 0.0068\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.7172e-04 - val_loss: 0.0067\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.6195e-04 - val_loss: 0.0066\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.5225e-04 - val_loss: 0.0065\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.4262e-04 - val_loss: 0.0064\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.3306e-04 - val_loss: 0.0063\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 847us/step - loss: 9.2357e-04 - val_loss: 0.0062\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.1416e-04 - val_loss: 0.0061\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.0481e-04 - val_loss: 0.0060\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.9554e-04 - val_loss: 0.0059\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.8633e-04 - val_loss: 0.0058\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.7720e-04 - val_loss: 0.0057\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.6814e-04 - val_loss: 0.0056\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5915e-04 - val_loss: 0.0055\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.5022e-04 - val_loss: 0.0055\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.4137e-04 - val_loss: 0.0054\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.3258e-04 - val_loss: 0.0053\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2387e-04 - val_loss: 0.0052\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.1522e-04 - val_loss: 0.0051\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.0664e-04 - val_loss: 0.0050\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.9813e-04 - val_loss: 0.0050\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.8969e-04 - val_loss: 0.0049\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.8131e-04 - val_loss: 0.0048\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.7301e-04 - val_loss: 0.0047\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.6477e-04 - val_loss: 0.0046\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.5660e-04 - val_loss: 0.0045\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.4849e-04 - val_loss: 0.0045\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.4045e-04 - val_loss: 0.0044\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.3248e-04 - val_loss: 0.0043\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.2457e-04 - val_loss: 0.0042\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.1673e-04 - val_loss: 0.0042\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.0896e-04 - val_loss: 0.0041\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.0125e-04 - val_loss: 0.0040\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.9360e-04 - val_loss: 0.0040\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.8602e-04 - val_loss: 0.0039\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.7851e-04 - val_loss: 0.0038\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.7106e-04 - val_loss: 0.0037\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.6367e-04 - val_loss: 0.0037\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.5635e-04 - val_loss: 0.0036\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4909e-04 - val_loss: 0.0035\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.4189e-04 - val_loss: 0.0035\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.3476e-04 - val_loss: 0.0034\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.2768e-04 - val_loss: 0.0034\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.2068e-04 - val_loss: 0.0033\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1373e-04 - val_loss: 0.0032\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0684e-04 - val_loss: 0.0032\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0002e-04 - val_loss: 0.0031\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9325e-04 - val_loss: 0.0030\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8655e-04 - val_loss: 0.0030\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.7991e-04 - val_loss: 0.0029\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7333e-04 - val_loss: 0.0029\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6681e-04 - val_loss: 0.0028\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6035e-04 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5394e-04 - val_loss: 0.0027\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.4760e-04 - val_loss: 0.0026\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4131e-04 - val_loss: 0.0026\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3509e-04 - val_loss: 0.0025\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2892e-04 - val_loss: 0.0025\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.2281e-04 - val_loss: 0.0024\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1675e-04 - val_loss: 0.0024\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1076e-04 - val_loss: 0.0023\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.0482e-04 - val_loss: 0.0023\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.9893e-04 - val_loss: 0.0022\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.9311e-04 - val_loss: 0.0022\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.8733e-04 - val_loss: 0.0021\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.8162e-04 - val_loss: 0.0021\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.7596e-04 - val_loss: 0.0020\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.7035e-04 - val_loss: 0.0020\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.6480e-04 - val_loss: 0.0020\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.5930e-04 - val_loss: 0.0019\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5386e-04 - val_loss: 0.0019\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4847e-04 - val_loss: 0.0018\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4314e-04 - val_loss: 0.0018\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.3785e-04 - val_loss: 0.0017\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.3262e-04 - val_loss: 0.0017\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.2744e-04 - val_loss: 0.0017\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2232e-04 - val_loss: 0.0016\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.1724e-04 - val_loss: 0.0016\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1222e-04 - val_loss: 0.0015\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0725e-04 - val_loss: 0.0015\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0232e-04 - val_loss: 0.0015\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9745e-04 - val_loss: 0.0014\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9263e-04 - val_loss: 0.0014\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.8786e-04 - val_loss: 0.0014\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.8314e-04 - val_loss: 0.0013\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7846e-04 - val_loss: 0.0013\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.7384e-04 - val_loss: 0.0013\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.6926e-04 - val_loss: 0.0012\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6473e-04 - val_loss: 0.0012\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6025e-04 - val_loss: 0.0012\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.5582e-04 - val_loss: 0.0011\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5143e-04 - val_loss: 0.0011\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.4709e-04 - val_loss: 0.0011\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4279e-04 - val_loss: 0.0010\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3854e-04 - val_loss: 0.0010\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.3434e-04 - val_loss: 9.8900e-04\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.3018e-04 - val_loss: 9.6115e-04\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.2607e-04 - val_loss: 9.3382e-04\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.2200e-04 - val_loss: 9.0701e-04\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.1798e-04 - val_loss: 8.8071e-04\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1400e-04 - val_loss: 8.5491e-04\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.1006e-04 - val_loss: 8.2962e-04\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.0617e-04 - val_loss: 8.0482e-04\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.0232e-04 - val_loss: 7.8053e-04\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9851e-04 - val_loss: 7.5670e-04\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9475e-04 - val_loss: 7.3337e-04\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9103e-04 - val_loss: 7.1051e-04\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8734e-04 - val_loss: 6.8812e-04\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=800, validation_data=(valX, valY), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a line plot showing the train and validation loss meeting.\n",
    "\n",
    "Ideally, we would like to see model performance like this if possible, although this may not be possible on challenging problems with a lot of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt06Q5AEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4272fab518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Overfit Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overfit model is one where performance on the train set is good and continues to improve, whereas performance on the validation set improves to a point and then begins to degrade.\n",
    "\n",
    "This can be diagnosed from a plot where the train loss slopes down and the validation loss slopes down, hits an inflection point, and starts to slope up again.\n",
    "\n",
    "The example below demonstrates an overfit LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/1200\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0980 - val_loss: 0.5646\n",
      "Epoch 2/1200\n",
      "5/5 [==============================] - 0s 738us/step - loss: 0.0968 - val_loss: 0.5601\n",
      "Epoch 3/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.5557\n",
      "Epoch 4/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.5513\n",
      "Epoch 5/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.5469\n",
      "Epoch 6/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.5425\n",
      "Epoch 7/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.5381\n",
      "Epoch 8/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0893 - val_loss: 0.5337\n",
      "Epoch 9/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0881 - val_loss: 0.5294\n",
      "Epoch 10/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.5250\n",
      "Epoch 11/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0857 - val_loss: 0.5207\n",
      "Epoch 12/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.5164\n",
      "Epoch 13/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.5121\n",
      "Epoch 14/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0822 - val_loss: 0.5078\n",
      "Epoch 15/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.5035\n",
      "Epoch 16/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0799 - val_loss: 0.4993\n",
      "Epoch 17/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.4951\n",
      "Epoch 18/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.4908\n",
      "Epoch 19/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0765 - val_loss: 0.4866\n",
      "Epoch 20/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0754 - val_loss: 0.4824\n",
      "Epoch 21/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.4782\n",
      "Epoch 22/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0731 - val_loss: 0.4741\n",
      "Epoch 23/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.4699\n",
      "Epoch 24/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.4658\n",
      "Epoch 25/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - val_loss: 0.4616\n",
      "Epoch 26/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.4575\n",
      "Epoch 27/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.4534\n",
      "Epoch 28/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.4494\n",
      "Epoch 29/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0657 - val_loss: 0.4453\n",
      "Epoch 30/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - val_loss: 0.4412\n",
      "Epoch 31/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0636 - val_loss: 0.4372\n",
      "Epoch 32/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - val_loss: 0.4332\n",
      "Epoch 33/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.4292\n",
      "Epoch 34/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - val_loss: 0.4252\n",
      "Epoch 35/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.4212\n",
      "Epoch 36/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0587 - val_loss: 0.4172\n",
      "Epoch 37/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.4132\n",
      "Epoch 38/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.4093\n",
      "Epoch 39/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.4054\n",
      "Epoch 40/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.4015\n",
      "Epoch 41/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.3976\n",
      "Epoch 42/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0530 - val_loss: 0.3937\n",
      "Epoch 43/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0521 - val_loss: 0.3898\n",
      "Epoch 44/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.3860\n",
      "Epoch 45/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0503 - val_loss: 0.3822\n",
      "Epoch 46/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.3784\n",
      "Epoch 47/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0485 - val_loss: 0.3746\n",
      "Epoch 48/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0477 - val_loss: 0.3708\n",
      "Epoch 49/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.3670\n",
      "Epoch 50/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0460 - val_loss: 0.3633\n",
      "Epoch 51/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.3596\n",
      "Epoch 52/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0443 - val_loss: 0.3559\n",
      "Epoch 53/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.3522\n",
      "Epoch 54/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.3485\n",
      "Epoch 55/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.3448\n",
      "Epoch 56/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.3412\n",
      "Epoch 57/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.3376\n",
      "Epoch 58/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0396 - val_loss: 0.3340\n",
      "Epoch 59/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0389 - val_loss: 0.3304\n",
      "Epoch 60/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.3269\n",
      "Epoch 61/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.3234\n",
      "Epoch 62/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.3199\n",
      "Epoch 63/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.3164\n",
      "Epoch 64/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0353 - val_loss: 0.3129\n",
      "Epoch 65/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0346 - val_loss: 0.3095\n",
      "Epoch 66/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.3061\n",
      "Epoch 67/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.3027\n",
      "Epoch 68/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0326 - val_loss: 0.2993\n",
      "Epoch 69/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - val_loss: 0.2959\n",
      "Epoch 70/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.2926\n",
      "Epoch 71/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.2893\n",
      "Epoch 72/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.2860\n",
      "Epoch 73/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.2828\n",
      "Epoch 74/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0288 - val_loss: 0.2796\n",
      "Epoch 75/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.2763\n",
      "Epoch 76/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.2732\n",
      "Epoch 77/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.2700\n",
      "Epoch 78/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.2669\n",
      "Epoch 79/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.2638\n",
      "Epoch 80/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.2607\n",
      "Epoch 81/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.2577\n",
      "Epoch 82/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0245 - val_loss: 0.2547\n",
      "Epoch 83/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0240 - val_loss: 0.2517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.2487\n",
      "Epoch 85/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.2458\n",
      "Epoch 86/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.2429\n",
      "Epoch 87/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.2400\n",
      "Epoch 88/1200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.2372\n",
      "Epoch 89/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.2343\n",
      "Epoch 90/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - val_loss: 0.2315\n",
      "Epoch 91/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - val_loss: 0.2288\n",
      "Epoch 92/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.2261\n",
      "Epoch 93/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.2234\n",
      "Epoch 94/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.2207\n",
      "Epoch 95/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.2180\n",
      "Epoch 96/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.2154\n",
      "Epoch 97/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.2129\n",
      "Epoch 98/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.2103\n",
      "Epoch 99/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.2078\n",
      "Epoch 100/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.2053\n",
      "Epoch 101/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.2028\n",
      "Epoch 102/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.2004\n",
      "Epoch 103/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.1980\n",
      "Epoch 104/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.1957\n",
      "Epoch 105/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.1933\n",
      "Epoch 106/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.1910\n",
      "Epoch 107/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1888\n",
      "Epoch 108/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.1865\n",
      "Epoch 109/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1843\n",
      "Epoch 110/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.1822\n",
      "Epoch 111/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1800\n",
      "Epoch 112/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1779\n",
      "Epoch 113/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1758\n",
      "Epoch 114/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.1738\n",
      "Epoch 115/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.1718\n",
      "Epoch 116/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.1698\n",
      "Epoch 117/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1678\n",
      "Epoch 118/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.1659\n",
      "Epoch 119/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.1640\n",
      "Epoch 120/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1621\n",
      "Epoch 121/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.1603\n",
      "Epoch 122/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.1585\n",
      "Epoch 123/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1568\n",
      "Epoch 124/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.1550\n",
      "Epoch 125/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1533\n",
      "Epoch 126/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.1516\n",
      "Epoch 127/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.1500\n",
      "Epoch 128/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.1484\n",
      "Epoch 129/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.1468\n",
      "Epoch 130/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.1452\n",
      "Epoch 131/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.1437\n",
      "Epoch 132/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1422\n",
      "Epoch 133/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1407\n",
      "Epoch 134/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1393\n",
      "Epoch 135/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1379\n",
      "Epoch 136/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.1365\n",
      "Epoch 137/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1351\n",
      "Epoch 138/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1338\n",
      "Epoch 139/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.1325\n",
      "Epoch 140/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1312\n",
      "Epoch 141/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.1299\n",
      "Epoch 142/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.1287\n",
      "Epoch 143/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.1275\n",
      "Epoch 144/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.1263\n",
      "Epoch 145/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.1252\n",
      "Epoch 146/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.1240\n",
      "Epoch 147/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.1229\n",
      "Epoch 148/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.1218\n",
      "Epoch 149/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.1208\n",
      "Epoch 150/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.1197\n",
      "Epoch 151/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.1187\n",
      "Epoch 152/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.1177\n",
      "Epoch 153/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.1168\n",
      "Epoch 154/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.1158\n",
      "Epoch 155/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1149\n",
      "Epoch 156/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.1140\n",
      "Epoch 157/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1131\n",
      "Epoch 158/1200\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.0086 - val_loss: 0.1122\n",
      "Epoch 159/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.1114\n",
      "Epoch 160/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.1106\n",
      "Epoch 161/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.1097\n",
      "Epoch 162/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.1089\n",
      "Epoch 163/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.1082\n",
      "Epoch 164/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.1074\n",
      "Epoch 165/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.1067\n",
      "Epoch 166/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.1052\n",
      "Epoch 168/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1045\n",
      "Epoch 169/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1039\n",
      "Epoch 170/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1032\n",
      "Epoch 171/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1026\n",
      "Epoch 172/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.1019\n",
      "Epoch 173/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.1013\n",
      "Epoch 174/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.1007\n",
      "Epoch 175/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.1001\n",
      "Epoch 176/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0995\n",
      "Epoch 177/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0989\n",
      "Epoch 178/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0984\n",
      "Epoch 179/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0978\n",
      "Epoch 180/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0973\n",
      "Epoch 181/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0968\n",
      "Epoch 182/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0963\n",
      "Epoch 183/1200\n",
      "5/5 [==============================] - 0s 777us/step - loss: 0.0079 - val_loss: 0.0957\n",
      "Epoch 184/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0953\n",
      "Epoch 185/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0948\n",
      "Epoch 186/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0943\n",
      "Epoch 187/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0938\n",
      "Epoch 188/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0934\n",
      "Epoch 189/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0929\n",
      "Epoch 190/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0925\n",
      "Epoch 191/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0920\n",
      "Epoch 192/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0916\n",
      "Epoch 193/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0912\n",
      "Epoch 194/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0908\n",
      "Epoch 195/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0903\n",
      "Epoch 196/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0899\n",
      "Epoch 197/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0895\n",
      "Epoch 198/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0892\n",
      "Epoch 199/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0888\n",
      "Epoch 200/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0884\n",
      "Epoch 201/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0880\n",
      "Epoch 202/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0876\n",
      "Epoch 203/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0873\n",
      "Epoch 204/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0869\n",
      "Epoch 205/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0866\n",
      "Epoch 206/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0862\n",
      "Epoch 207/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0859\n",
      "Epoch 208/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0855\n",
      "Epoch 209/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0852\n",
      "Epoch 210/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0848\n",
      "Epoch 211/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0845\n",
      "Epoch 212/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0842\n",
      "Epoch 213/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0838\n",
      "Epoch 214/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0835\n",
      "Epoch 215/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0832\n",
      "Epoch 216/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0828\n",
      "Epoch 217/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0825\n",
      "Epoch 218/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0822\n",
      "Epoch 219/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0819\n",
      "Epoch 220/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0816\n",
      "Epoch 221/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0813\n",
      "Epoch 222/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0809\n",
      "Epoch 223/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0806\n",
      "Epoch 224/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0803\n",
      "Epoch 225/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0800\n",
      "Epoch 226/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0797\n",
      "Epoch 227/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0794\n",
      "Epoch 228/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0791\n",
      "Epoch 229/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0788\n",
      "Epoch 230/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0785\n",
      "Epoch 231/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0782\n",
      "Epoch 232/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0779\n",
      "Epoch 233/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0776\n",
      "Epoch 234/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0773\n",
      "Epoch 235/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0770\n",
      "Epoch 236/1200\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.0067 - val_loss: 0.0767\n",
      "Epoch 237/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0764\n",
      "Epoch 238/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0761\n",
      "Epoch 239/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0758\n",
      "Epoch 240/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0755\n",
      "Epoch 241/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0752\n",
      "Epoch 242/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0749\n",
      "Epoch 243/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0746\n",
      "Epoch 244/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0743\n",
      "Epoch 245/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0741\n",
      "Epoch 246/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0738\n",
      "Epoch 247/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0735\n",
      "Epoch 248/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0729\n",
      "Epoch 250/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0726\n",
      "Epoch 251/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0723\n",
      "Epoch 252/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0720\n",
      "Epoch 253/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0717\n",
      "Epoch 254/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0714\n",
      "Epoch 255/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0711\n",
      "Epoch 256/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0708\n",
      "Epoch 257/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0706\n",
      "Epoch 258/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0703\n",
      "Epoch 259/1200\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.0062 - val_loss: 0.0700\n",
      "Epoch 260/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0697\n",
      "Epoch 261/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0694\n",
      "Epoch 262/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0691\n",
      "Epoch 263/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0688\n",
      "Epoch 264/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0685\n",
      "Epoch 265/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0682\n",
      "Epoch 266/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0679\n",
      "Epoch 267/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0676\n",
      "Epoch 268/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0674\n",
      "Epoch 269/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0671\n",
      "Epoch 270/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0668\n",
      "Epoch 271/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0665\n",
      "Epoch 272/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0662\n",
      "Epoch 273/1200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0659\n",
      "Epoch 274/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0656\n",
      "Epoch 275/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0653\n",
      "Epoch 276/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0650\n",
      "Epoch 277/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0647\n",
      "Epoch 278/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0645\n",
      "Epoch 279/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0642\n",
      "Epoch 280/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0639\n",
      "Epoch 281/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0636\n",
      "Epoch 282/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0633\n",
      "Epoch 283/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0630\n",
      "Epoch 284/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0627\n",
      "Epoch 285/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0624\n",
      "Epoch 286/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0621\n",
      "Epoch 287/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0619\n",
      "Epoch 288/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0616\n",
      "Epoch 289/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0613\n",
      "Epoch 290/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0610\n",
      "Epoch 291/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0607\n",
      "Epoch 292/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0604\n",
      "Epoch 293/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0601\n",
      "Epoch 294/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0598\n",
      "Epoch 295/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0595\n",
      "Epoch 296/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0593\n",
      "Epoch 297/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0590\n",
      "Epoch 298/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0587\n",
      "Epoch 299/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0584\n",
      "Epoch 300/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0581\n",
      "Epoch 301/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0578\n",
      "Epoch 302/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0575\n",
      "Epoch 303/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0573\n",
      "Epoch 304/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0570\n",
      "Epoch 305/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0567\n",
      "Epoch 306/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0564\n",
      "Epoch 307/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0561\n",
      "Epoch 308/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0558\n",
      "Epoch 309/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0556\n",
      "Epoch 310/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0553\n",
      "Epoch 311/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0550\n",
      "Epoch 312/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0547\n",
      "Epoch 313/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0544\n",
      "Epoch 314/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0541\n",
      "Epoch 315/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0539\n",
      "Epoch 316/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0536\n",
      "Epoch 317/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0533\n",
      "Epoch 318/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0530\n",
      "Epoch 319/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0527\n",
      "Epoch 320/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0525\n",
      "Epoch 321/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0522\n",
      "Epoch 322/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0519\n",
      "Epoch 323/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0516\n",
      "Epoch 324/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0513\n",
      "Epoch 325/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0511\n",
      "Epoch 326/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0508\n",
      "Epoch 327/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0505\n",
      "Epoch 328/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0502\n",
      "Epoch 329/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0499\n",
      "Epoch 330/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0494\n",
      "Epoch 332/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0491\n",
      "Epoch 333/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0488\n",
      "Epoch 334/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0486\n",
      "Epoch 335/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0483\n",
      "Epoch 336/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0480\n",
      "Epoch 337/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0477\n",
      "Epoch 338/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0475\n",
      "Epoch 339/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0472\n",
      "Epoch 340/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0469\n",
      "Epoch 341/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0467\n",
      "Epoch 342/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0464\n",
      "Epoch 343/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0461\n",
      "Epoch 344/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0458\n",
      "Epoch 345/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0456\n",
      "Epoch 346/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0453\n",
      "Epoch 347/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0450\n",
      "Epoch 348/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0448\n",
      "Epoch 349/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0445\n",
      "Epoch 350/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0442\n",
      "Epoch 351/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0440\n",
      "Epoch 352/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0437\n",
      "Epoch 353/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0434\n",
      "Epoch 354/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0432\n",
      "Epoch 355/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0429\n",
      "Epoch 356/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0426\n",
      "Epoch 357/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0424\n",
      "Epoch 358/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0421\n",
      "Epoch 359/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0418\n",
      "Epoch 360/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0416\n",
      "Epoch 361/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0413\n",
      "Epoch 362/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0411\n",
      "Epoch 363/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0408\n",
      "Epoch 364/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0405\n",
      "Epoch 365/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0403\n",
      "Epoch 366/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0400\n",
      "Epoch 367/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0398\n",
      "Epoch 368/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0395\n",
      "Epoch 369/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0393\n",
      "Epoch 370/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0390\n",
      "Epoch 371/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0387\n",
      "Epoch 372/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0385\n",
      "Epoch 373/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0382\n",
      "Epoch 374/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0380\n",
      "Epoch 375/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0377\n",
      "Epoch 376/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0375\n",
      "Epoch 377/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0372\n",
      "Epoch 378/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0370\n",
      "Epoch 379/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0367\n",
      "Epoch 380/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0365\n",
      "Epoch 381/1200\n",
      "5/5 [==============================] - 0s 793us/step - loss: 0.0037 - val_loss: 0.0362\n",
      "Epoch 382/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0360\n",
      "Epoch 383/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0357\n",
      "Epoch 384/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0355\n",
      "Epoch 385/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0352\n",
      "Epoch 386/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0350\n",
      "Epoch 387/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0347\n",
      "Epoch 388/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0345\n",
      "Epoch 389/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0342\n",
      "Epoch 390/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0340\n",
      "Epoch 391/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0337\n",
      "Epoch 392/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0335\n",
      "Epoch 393/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0333\n",
      "Epoch 394/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0330\n",
      "Epoch 395/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0328\n",
      "Epoch 396/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0325\n",
      "Epoch 397/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0323\n",
      "Epoch 398/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0321\n",
      "Epoch 399/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0318\n",
      "Epoch 400/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0316\n",
      "Epoch 401/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0314\n",
      "Epoch 402/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0311\n",
      "Epoch 403/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0309\n",
      "Epoch 404/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0307\n",
      "Epoch 405/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0304\n",
      "Epoch 406/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0302\n",
      "Epoch 407/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0300\n",
      "Epoch 408/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0297\n",
      "Epoch 409/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0295\n",
      "Epoch 410/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0293\n",
      "Epoch 411/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0290\n",
      "Epoch 412/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0286\n",
      "Epoch 414/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0284\n",
      "Epoch 415/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0281\n",
      "Epoch 416/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0279\n",
      "Epoch 417/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0277\n",
      "Epoch 418/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0275\n",
      "Epoch 419/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0272\n",
      "Epoch 420/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0270\n",
      "Epoch 421/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0268\n",
      "Epoch 422/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0266\n",
      "Epoch 423/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0264\n",
      "Epoch 424/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0261\n",
      "Epoch 425/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0259\n",
      "Epoch 426/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0257\n",
      "Epoch 427/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0255\n",
      "Epoch 428/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0253\n",
      "Epoch 429/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0251\n",
      "Epoch 430/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0248\n",
      "Epoch 431/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0246\n",
      "Epoch 432/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0244\n",
      "Epoch 433/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0242\n",
      "Epoch 434/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0240\n",
      "Epoch 435/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0238\n",
      "Epoch 436/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0236\n",
      "Epoch 437/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0234\n",
      "Epoch 438/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0232\n",
      "Epoch 439/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0230\n",
      "Epoch 440/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0228\n",
      "Epoch 441/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0226\n",
      "Epoch 442/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0223\n",
      "Epoch 443/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0221\n",
      "Epoch 444/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0219\n",
      "Epoch 445/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0217\n",
      "Epoch 446/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0215\n",
      "Epoch 447/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0213\n",
      "Epoch 448/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0211\n",
      "Epoch 449/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0210\n",
      "Epoch 450/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0208\n",
      "Epoch 451/1200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0206\n",
      "Epoch 452/1200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0204\n",
      "Epoch 453/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0202\n",
      "Epoch 454/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0200\n",
      "Epoch 455/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0198\n",
      "Epoch 456/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0196\n",
      "Epoch 457/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0194\n",
      "Epoch 458/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0192\n",
      "Epoch 459/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0190\n",
      "Epoch 460/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0188\n",
      "Epoch 461/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0187\n",
      "Epoch 462/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0185\n",
      "Epoch 463/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0183\n",
      "Epoch 464/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0181\n",
      "Epoch 465/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0179\n",
      "Epoch 466/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0177\n",
      "Epoch 467/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0176\n",
      "Epoch 468/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0174\n",
      "Epoch 469/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0172\n",
      "Epoch 470/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0170\n",
      "Epoch 471/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0169\n",
      "Epoch 472/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0167\n",
      "Epoch 473/1200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0165\n",
      "Epoch 474/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0163\n",
      "Epoch 475/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0162\n",
      "Epoch 476/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0160\n",
      "Epoch 477/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0158\n",
      "Epoch 478/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0157\n",
      "Epoch 479/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0155\n",
      "Epoch 480/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0153\n",
      "Epoch 481/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0151\n",
      "Epoch 482/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0150\n",
      "Epoch 483/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0148\n",
      "Epoch 484/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0147\n",
      "Epoch 485/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0145\n",
      "Epoch 486/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0143\n",
      "Epoch 487/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0142\n",
      "Epoch 488/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0140\n",
      "Epoch 489/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0139\n",
      "Epoch 490/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0137\n",
      "Epoch 491/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0135\n",
      "Epoch 492/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0134\n",
      "Epoch 493/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0132\n",
      "Epoch 494/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0129\n",
      "Epoch 496/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0128\n",
      "Epoch 497/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0126\n",
      "Epoch 498/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0125\n",
      "Epoch 499/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0123\n",
      "Epoch 500/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0122\n",
      "Epoch 501/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0120\n",
      "Epoch 502/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0119\n",
      "Epoch 503/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0117\n",
      "Epoch 504/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0116\n",
      "Epoch 505/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0114\n",
      "Epoch 506/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0113\n",
      "Epoch 507/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0112\n",
      "Epoch 508/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0110\n",
      "Epoch 509/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0109\n",
      "Epoch 510/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0107\n",
      "Epoch 511/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0106\n",
      "Epoch 512/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0105\n",
      "Epoch 513/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0103\n",
      "Epoch 514/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0102\n",
      "Epoch 515/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0101\n",
      "Epoch 516/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0099\n",
      "Epoch 517/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0098\n",
      "Epoch 518/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0097\n",
      "Epoch 519/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0096\n",
      "Epoch 520/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0094\n",
      "Epoch 521/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0093\n",
      "Epoch 522/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0092\n",
      "Epoch 523/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0091\n",
      "Epoch 524/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0089\n",
      "Epoch 525/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0088\n",
      "Epoch 526/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0087\n",
      "Epoch 527/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0086\n",
      "Epoch 528/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0084\n",
      "Epoch 529/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0083\n",
      "Epoch 530/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0082\n",
      "Epoch 531/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0081\n",
      "Epoch 532/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0080\n",
      "Epoch 533/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0079\n",
      "Epoch 534/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0077\n",
      "Epoch 535/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0076\n",
      "Epoch 536/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 537/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0074\n",
      "Epoch 538/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 539/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 540/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 541/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 542/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 543/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0068\n",
      "Epoch 544/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0067\n",
      "Epoch 545/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 546/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0065\n",
      "Epoch 547/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0064\n",
      "Epoch 548/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 549/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0062\n",
      "Epoch 550/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0061\n",
      "Epoch 551/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0060\n",
      "Epoch 552/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0059\n",
      "Epoch 553/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0058\n",
      "Epoch 554/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0057\n",
      "Epoch 555/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0056\n",
      "Epoch 556/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 557/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 558/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.9123e-04 - val_loss: 0.0053\n",
      "Epoch 559/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.8153e-04 - val_loss: 0.0052\n",
      "Epoch 560/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.7189e-04 - val_loss: 0.0051\n",
      "Epoch 561/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.6232e-04 - val_loss: 0.0050\n",
      "Epoch 562/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.5281e-04 - val_loss: 0.0050\n",
      "Epoch 563/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.4337e-04 - val_loss: 0.0049\n",
      "Epoch 564/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.3399e-04 - val_loss: 0.0048\n",
      "Epoch 565/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.2468e-04 - val_loss: 0.0047\n",
      "Epoch 566/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.1544e-04 - val_loss: 0.0046\n",
      "Epoch 567/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.0626e-04 - val_loss: 0.0045\n",
      "Epoch 568/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.9715e-04 - val_loss: 0.0045\n",
      "Epoch 569/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.8810e-04 - val_loss: 0.0044\n",
      "Epoch 570/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.7911e-04 - val_loss: 0.0043\n",
      "Epoch 571/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.7019e-04 - val_loss: 0.0042\n",
      "Epoch 572/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.6134e-04 - val_loss: 0.0041\n",
      "Epoch 573/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5254e-04 - val_loss: 0.0041\n",
      "Epoch 574/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.4382e-04 - val_loss: 0.0040\n",
      "Epoch 575/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.3516e-04 - val_loss: 0.0039\n",
      "Epoch 576/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.2656e-04 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.1802e-04 - val_loss: 0.0038\n",
      "Epoch 578/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.0955e-04 - val_loss: 0.0037\n",
      "Epoch 579/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.0115e-04 - val_loss: 0.0036\n",
      "Epoch 580/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.9281e-04 - val_loss: 0.0035\n",
      "Epoch 581/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.8453e-04 - val_loss: 0.0035\n",
      "Epoch 582/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.7631e-04 - val_loss: 0.0034\n",
      "Epoch 583/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.6816e-04 - val_loss: 0.0033\n",
      "Epoch 584/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.6007e-04 - val_loss: 0.0033\n",
      "Epoch 585/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.5204e-04 - val_loss: 0.0032\n",
      "Epoch 586/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.4407e-04 - val_loss: 0.0031\n",
      "Epoch 587/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.3617e-04 - val_loss: 0.0031\n",
      "Epoch 588/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.2833e-04 - val_loss: 0.0030\n",
      "Epoch 589/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2055e-04 - val_loss: 0.0029\n",
      "Epoch 590/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.1283e-04 - val_loss: 0.0029\n",
      "Epoch 591/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.0518e-04 - val_loss: 0.0028\n",
      "Epoch 592/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.9759e-04 - val_loss: 0.0028\n",
      "Epoch 593/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.9005e-04 - val_loss: 0.0027\n",
      "Epoch 594/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.8258e-04 - val_loss: 0.0026\n",
      "Epoch 595/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7517e-04 - val_loss: 0.0026\n",
      "Epoch 596/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.6782e-04 - val_loss: 0.0025\n",
      "Epoch 597/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.6053e-04 - val_loss: 0.0025\n",
      "Epoch 598/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.5330e-04 - val_loss: 0.0024\n",
      "Epoch 599/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.4613e-04 - val_loss: 0.0024\n",
      "Epoch 600/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3903e-04 - val_loss: 0.0023\n",
      "Epoch 601/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.3198e-04 - val_loss: 0.0023\n",
      "Epoch 602/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.2499e-04 - val_loss: 0.0022\n",
      "Epoch 603/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.1806e-04 - val_loss: 0.0022\n",
      "Epoch 604/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1118e-04 - val_loss: 0.0021\n",
      "Epoch 605/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0437e-04 - val_loss: 0.0021\n",
      "Epoch 606/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9762e-04 - val_loss: 0.0020\n",
      "Epoch 607/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9092e-04 - val_loss: 0.0020\n",
      "Epoch 608/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.8428e-04 - val_loss: 0.0019\n",
      "Epoch 609/1200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.7770e-04 - val_loss: 0.0019\n",
      "Epoch 610/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7118e-04 - val_loss: 0.0018\n",
      "Epoch 611/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6471e-04 - val_loss: 0.0018\n",
      "Epoch 612/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5831e-04 - val_loss: 0.0017\n",
      "Epoch 613/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5195e-04 - val_loss: 0.0017\n",
      "Epoch 614/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.4566e-04 - val_loss: 0.0016\n",
      "Epoch 615/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.3942e-04 - val_loss: 0.0016\n",
      "Epoch 616/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.3324e-04 - val_loss: 0.0015\n",
      "Epoch 617/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2711e-04 - val_loss: 0.0015\n",
      "Epoch 618/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.2104e-04 - val_loss: 0.0015\n",
      "Epoch 619/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1503e-04 - val_loss: 0.0014\n",
      "Epoch 620/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.0907e-04 - val_loss: 0.0014\n",
      "Epoch 621/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.0316e-04 - val_loss: 0.0013\n",
      "Epoch 622/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.9731e-04 - val_loss: 0.0013\n",
      "Epoch 623/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.9151e-04 - val_loss: 0.0013\n",
      "Epoch 624/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.8577e-04 - val_loss: 0.0012\n",
      "Epoch 625/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.8008e-04 - val_loss: 0.0012\n",
      "Epoch 626/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.7445e-04 - val_loss: 0.0012\n",
      "Epoch 627/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.6887e-04 - val_loss: 0.0011\n",
      "Epoch 628/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.6334e-04 - val_loss: 0.0011\n",
      "Epoch 629/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5786e-04 - val_loss: 0.0011\n",
      "Epoch 630/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5244e-04 - val_loss: 0.0010\n",
      "Epoch 631/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.4707e-04 - val_loss: 0.0010\n",
      "Epoch 632/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.4175e-04 - val_loss: 9.7054e-04\n",
      "Epoch 633/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.3648e-04 - val_loss: 9.3994e-04\n",
      "Epoch 634/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3126e-04 - val_loss: 9.0997e-04\n",
      "Epoch 635/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.2610e-04 - val_loss: 8.8062e-04\n",
      "Epoch 636/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.2098e-04 - val_loss: 8.5188e-04\n",
      "Epoch 637/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.1592e-04 - val_loss: 8.2375e-04\n",
      "Epoch 638/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1091e-04 - val_loss: 7.9623e-04\n",
      "Epoch 639/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0594e-04 - val_loss: 7.6931e-04\n",
      "Epoch 640/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0103e-04 - val_loss: 7.4297e-04\n",
      "Epoch 641/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9616e-04 - val_loss: 7.1723e-04\n",
      "Epoch 642/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9135e-04 - val_loss: 6.9207e-04\n",
      "Epoch 643/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.8658e-04 - val_loss: 6.6748e-04\n",
      "Epoch 644/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.8186e-04 - val_loss: 6.4348e-04\n",
      "Epoch 645/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7719e-04 - val_loss: 6.2004e-04\n",
      "Epoch 646/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7257e-04 - val_loss: 5.9716e-04\n",
      "Epoch 647/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6799e-04 - val_loss: 5.7483e-04\n",
      "Epoch 648/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.6346e-04 - val_loss: 5.5306e-04\n",
      "Epoch 649/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.5898e-04 - val_loss: 5.3184e-04\n",
      "Epoch 650/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.5455e-04 - val_loss: 5.1115e-04\n",
      "Epoch 651/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.5016e-04 - val_loss: 4.9100e-04\n",
      "Epoch 652/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.4582e-04 - val_loss: 4.7139e-04\n",
      "Epoch 653/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.4152e-04 - val_loss: 4.5229e-04\n",
      "Epoch 654/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.3727e-04 - val_loss: 4.3372e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.3306e-04 - val_loss: 4.1566e-04\n",
      "Epoch 656/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.2890e-04 - val_loss: 3.9811e-04\n",
      "Epoch 657/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.2479e-04 - val_loss: 3.8107e-04\n",
      "Epoch 658/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2071e-04 - val_loss: 3.6453e-04\n",
      "Epoch 659/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.1669e-04 - val_loss: 3.4847e-04\n",
      "Epoch 660/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.1270e-04 - val_loss: 3.3291e-04\n",
      "Epoch 661/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.0876e-04 - val_loss: 3.1783e-04\n",
      "Epoch 662/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.0486e-04 - val_loss: 3.0323e-04\n",
      "Epoch 663/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.0101e-04 - val_loss: 2.8910e-04\n",
      "Epoch 664/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9719e-04 - val_loss: 2.7544e-04\n",
      "Epoch 665/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9342e-04 - val_loss: 2.6224e-04\n",
      "Epoch 666/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.8969e-04 - val_loss: 2.4950e-04\n",
      "Epoch 667/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.8601e-04 - val_loss: 2.3721e-04\n",
      "Epoch 668/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8236e-04 - val_loss: 2.2537e-04\n",
      "Epoch 669/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7875e-04 - val_loss: 2.1396e-04\n",
      "Epoch 670/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.7519e-04 - val_loss: 2.0300e-04\n",
      "Epoch 671/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.7166e-04 - val_loss: 1.9247e-04\n",
      "Epoch 672/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.6818e-04 - val_loss: 1.8236e-04\n",
      "Epoch 673/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6473e-04 - val_loss: 1.7268e-04\n",
      "Epoch 674/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6133e-04 - val_loss: 1.6341e-04\n",
      "Epoch 675/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5796e-04 - val_loss: 1.5455e-04\n",
      "Epoch 676/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5463e-04 - val_loss: 1.4610e-04\n",
      "Epoch 677/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5134e-04 - val_loss: 1.3804e-04\n",
      "Epoch 678/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4809e-04 - val_loss: 1.3039e-04\n",
      "Epoch 679/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.4488e-04 - val_loss: 1.2313e-04\n",
      "Epoch 680/1200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.4170e-04 - val_loss: 1.1625e-04\n",
      "Epoch 681/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3856e-04 - val_loss: 1.0975e-04\n",
      "Epoch 682/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3546e-04 - val_loss: 1.0363e-04\n",
      "Epoch 683/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3239e-04 - val_loss: 9.7879e-05\n",
      "Epoch 684/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.2937e-04 - val_loss: 9.2496e-05\n",
      "Epoch 685/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2637e-04 - val_loss: 8.7473e-05\n",
      "Epoch 686/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2341e-04 - val_loss: 8.2807e-05\n",
      "Epoch 687/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2049e-04 - val_loss: 7.8493e-05\n",
      "Epoch 688/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1760e-04 - val_loss: 7.4525e-05\n",
      "Epoch 689/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1475e-04 - val_loss: 7.0899e-05\n",
      "Epoch 690/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1194e-04 - val_loss: 6.7610e-05\n",
      "Epoch 691/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0915e-04 - val_loss: 6.4652e-05\n",
      "Epoch 692/1200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.0640e-04 - val_loss: 6.2024e-05\n",
      "Epoch 693/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0368e-04 - val_loss: 5.9717e-05\n",
      "Epoch 694/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0100e-04 - val_loss: 5.7729e-05\n",
      "Epoch 695/1200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.9835e-04 - val_loss: 5.6054e-05\n",
      "Epoch 696/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9573e-04 - val_loss: 5.4689e-05\n",
      "Epoch 697/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9315e-04 - val_loss: 5.3628e-05\n",
      "Epoch 698/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9060e-04 - val_loss: 5.2865e-05\n",
      "Epoch 699/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.8808e-04 - val_loss: 5.2399e-05\n",
      "Epoch 700/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8559e-04 - val_loss: 5.2222e-05\n",
      "Epoch 701/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8313e-04 - val_loss: 5.2332e-05\n",
      "Epoch 702/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.8070e-04 - val_loss: 5.2724e-05\n",
      "Epoch 703/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.7830e-04 - val_loss: 5.3390e-05\n",
      "Epoch 704/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7594e-04 - val_loss: 5.4331e-05\n",
      "Epoch 705/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.7360e-04 - val_loss: 5.5539e-05\n",
      "Epoch 706/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7130e-04 - val_loss: 5.7012e-05\n",
      "Epoch 707/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6902e-04 - val_loss: 5.8744e-05\n",
      "Epoch 708/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6677e-04 - val_loss: 6.0730e-05\n",
      "Epoch 709/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.6455e-04 - val_loss: 6.2968e-05\n",
      "Epoch 710/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.6236e-04 - val_loss: 6.5452e-05\n",
      "Epoch 711/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6020e-04 - val_loss: 6.8178e-05\n",
      "Epoch 712/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5807e-04 - val_loss: 7.1142e-05\n",
      "Epoch 713/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5596e-04 - val_loss: 7.4341e-05\n",
      "Epoch 714/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5388e-04 - val_loss: 7.7769e-05\n",
      "Epoch 715/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.5183e-04 - val_loss: 8.1421e-05\n",
      "Epoch 716/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4981e-04 - val_loss: 8.5297e-05\n",
      "Epoch 717/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4781e-04 - val_loss: 8.9388e-05\n",
      "Epoch 718/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4584e-04 - val_loss: 9.3693e-05\n",
      "Epoch 719/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4390e-04 - val_loss: 9.8209e-05\n",
      "Epoch 720/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4198e-04 - val_loss: 1.0293e-04\n",
      "Epoch 721/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4008e-04 - val_loss: 1.0785e-04\n",
      "Epoch 722/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3822e-04 - val_loss: 1.1297e-04\n",
      "Epoch 723/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3637e-04 - val_loss: 1.1828e-04\n",
      "Epoch 724/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3456e-04 - val_loss: 1.2379e-04\n",
      "Epoch 725/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.3276e-04 - val_loss: 1.2947e-04\n",
      "Epoch 726/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3099e-04 - val_loss: 1.3534e-04\n",
      "Epoch 727/1200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2925e-04 - val_loss: 1.4139e-04\n",
      "Epoch 728/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2753e-04 - val_loss: 1.4762e-04\n",
      "Epoch 729/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2583e-04 - val_loss: 1.5401e-04\n",
      "Epoch 730/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2416e-04 - val_loss: 1.6058e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 731/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.2250e-04 - val_loss: 1.6730e-04\n",
      "Epoch 732/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.2088e-04 - val_loss: 1.7419e-04\n",
      "Epoch 733/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1927e-04 - val_loss: 1.8123e-04\n",
      "Epoch 734/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1769e-04 - val_loss: 1.8843e-04\n",
      "Epoch 735/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1613e-04 - val_loss: 1.9578e-04\n",
      "Epoch 736/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1459e-04 - val_loss: 2.0327e-04\n",
      "Epoch 737/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1307e-04 - val_loss: 2.1090e-04\n",
      "Epoch 738/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1157e-04 - val_loss: 2.1868e-04\n",
      "Epoch 739/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1010e-04 - val_loss: 2.2659e-04\n",
      "Epoch 740/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0864e-04 - val_loss: 2.3463e-04\n",
      "Epoch 741/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0721e-04 - val_loss: 2.4281e-04\n",
      "Epoch 742/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0579e-04 - val_loss: 2.5110e-04\n",
      "Epoch 743/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0440e-04 - val_loss: 2.5953e-04\n",
      "Epoch 744/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0302e-04 - val_loss: 2.6807e-04\n",
      "Epoch 745/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0167e-04 - val_loss: 2.7673e-04\n",
      "Epoch 746/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0034e-04 - val_loss: 2.8550e-04\n",
      "Epoch 747/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9020e-05 - val_loss: 2.9438e-04\n",
      "Epoch 748/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.7724e-05 - val_loss: 3.0338e-04\n",
      "Epoch 749/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6445e-05 - val_loss: 3.1247e-04\n",
      "Epoch 750/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.5186e-05 - val_loss: 3.2167e-04\n",
      "Epoch 751/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.3945e-05 - val_loss: 3.3096e-04\n",
      "Epoch 752/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.2723e-05 - val_loss: 3.4036e-04\n",
      "Epoch 753/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.1518e-05 - val_loss: 3.4984e-04\n",
      "Epoch 754/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.0330e-05 - val_loss: 3.5941e-04\n",
      "Epoch 755/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.9161e-05 - val_loss: 3.6908e-04\n",
      "Epoch 756/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.8008e-05 - val_loss: 3.7882e-04\n",
      "Epoch 757/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.6872e-05 - val_loss: 3.8865e-04\n",
      "Epoch 758/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.5754e-05 - val_loss: 3.9855e-04\n",
      "Epoch 759/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.4652e-05 - val_loss: 4.0853e-04\n",
      "Epoch 760/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.3566e-05 - val_loss: 4.1859e-04\n",
      "Epoch 761/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.2496e-05 - val_loss: 4.2872e-04\n",
      "Epoch 762/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.1443e-05 - val_loss: 4.3891e-04\n",
      "Epoch 763/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.0406e-05 - val_loss: 4.4917e-04\n",
      "Epoch 764/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.9383e-05 - val_loss: 4.5949e-04\n",
      "Epoch 765/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.8377e-05 - val_loss: 4.6988e-04\n",
      "Epoch 766/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.7385e-05 - val_loss: 4.8032e-04\n",
      "Epoch 767/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.6409e-05 - val_loss: 4.9082e-04\n",
      "Epoch 768/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.5448e-05 - val_loss: 5.0137e-04\n",
      "Epoch 769/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.4501e-05 - val_loss: 5.1198e-04\n",
      "Epoch 770/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.3569e-05 - val_loss: 5.2263e-04\n",
      "Epoch 771/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2650e-05 - val_loss: 5.3333e-04\n",
      "Epoch 772/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.1746e-05 - val_loss: 5.4407e-04\n",
      "Epoch 773/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.0856e-05 - val_loss: 5.5486e-04\n",
      "Epoch 774/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.9980e-05 - val_loss: 5.6569e-04\n",
      "Epoch 775/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.9117e-05 - val_loss: 5.7655e-04\n",
      "Epoch 776/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.8268e-05 - val_loss: 5.8745e-04\n",
      "Epoch 777/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.7431e-05 - val_loss: 5.9838e-04\n",
      "Epoch 778/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.6608e-05 - val_loss: 6.0935e-04\n",
      "Epoch 779/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5798e-05 - val_loss: 6.2034e-04\n",
      "Epoch 780/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.5000e-05 - val_loss: 6.3136e-04\n",
      "Epoch 781/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4214e-05 - val_loss: 6.4241e-04\n",
      "Epoch 782/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3442e-05 - val_loss: 6.5348e-04\n",
      "Epoch 783/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2681e-05 - val_loss: 6.6457e-04\n",
      "Epoch 784/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.1932e-05 - val_loss: 6.7568e-04\n",
      "Epoch 785/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1195e-05 - val_loss: 6.8681e-04\n",
      "Epoch 786/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.0470e-05 - val_loss: 6.9796e-04\n",
      "Epoch 787/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.9756e-05 - val_loss: 7.0912e-04\n",
      "Epoch 788/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.9054e-05 - val_loss: 7.2029e-04\n",
      "Epoch 789/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.8363e-05 - val_loss: 7.3148e-04\n",
      "Epoch 790/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7683e-05 - val_loss: 7.4267e-04\n",
      "Epoch 791/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.7014e-05 - val_loss: 7.5387e-04\n",
      "Epoch 792/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6355e-05 - val_loss: 7.6507e-04\n",
      "Epoch 793/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.5707e-05 - val_loss: 7.7628e-04\n",
      "Epoch 794/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5070e-05 - val_loss: 7.8750e-04\n",
      "Epoch 795/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.4443e-05 - val_loss: 7.9871e-04\n",
      "Epoch 796/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.3826e-05 - val_loss: 8.0992e-04\n",
      "Epoch 797/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3219e-05 - val_loss: 8.2113e-04\n",
      "Epoch 798/1200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.2622e-05 - val_loss: 8.3234e-04\n",
      "Epoch 799/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2035e-05 - val_loss: 8.4354e-04\n",
      "Epoch 800/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1457e-05 - val_loss: 8.5473e-04\n",
      "Epoch 801/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.0889e-05 - val_loss: 8.6592e-04\n",
      "Epoch 802/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.0331e-05 - val_loss: 8.7710e-04\n",
      "Epoch 803/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.9781e-05 - val_loss: 8.8826e-04\n",
      "Epoch 804/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.9240e-05 - val_loss: 8.9942e-04\n",
      "Epoch 805/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.8709e-05 - val_loss: 9.1056e-04\n",
      "Epoch 806/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.8186e-05 - val_loss: 9.2169e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 807/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.7672e-05 - val_loss: 9.3281e-04\n",
      "Epoch 808/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7166e-05 - val_loss: 9.4389e-04\n",
      "Epoch 809/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6669e-05 - val_loss: 9.5497e-04\n",
      "Epoch 810/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.6180e-05 - val_loss: 9.6603e-04\n",
      "Epoch 811/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5699e-05 - val_loss: 9.7707e-04\n",
      "Epoch 812/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.5227e-05 - val_loss: 9.8808e-04\n",
      "Epoch 813/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4762e-05 - val_loss: 9.9907e-04\n",
      "Epoch 814/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.4305e-05 - val_loss: 0.0010\n",
      "Epoch 815/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3856e-05 - val_loss: 0.0010\n",
      "Epoch 816/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.3414e-05 - val_loss: 0.0010\n",
      "Epoch 817/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.2980e-05 - val_loss: 0.0010\n",
      "Epoch 818/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.2553e-05 - val_loss: 0.0011\n",
      "Epoch 819/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.2134e-05 - val_loss: 0.0011\n",
      "Epoch 820/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1721e-05 - val_loss: 0.0011\n",
      "Epoch 821/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.1316e-05 - val_loss: 0.0011\n",
      "Epoch 822/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0917e-05 - val_loss: 0.0011\n",
      "Epoch 823/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0526e-05 - val_loss: 0.0011\n",
      "Epoch 824/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0141e-05 - val_loss: 0.0011\n",
      "Epoch 825/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9762e-05 - val_loss: 0.0011\n",
      "Epoch 826/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9391e-05 - val_loss: 0.0011\n",
      "Epoch 827/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.9025e-05 - val_loss: 0.0011\n",
      "Epoch 828/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8666e-05 - val_loss: 0.0012\n",
      "Epoch 829/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.8313e-05 - val_loss: 0.0012\n",
      "Epoch 830/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7967e-05 - val_loss: 0.0012\n",
      "Epoch 831/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7626e-05 - val_loss: 0.0012\n",
      "Epoch 832/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.7291e-05 - val_loss: 0.0012\n",
      "Epoch 833/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6962e-05 - val_loss: 0.0012\n",
      "Epoch 834/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.6639e-05 - val_loss: 0.0012\n",
      "Epoch 835/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.6321e-05 - val_loss: 0.0012\n",
      "Epoch 836/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.6009e-05 - val_loss: 0.0012\n",
      "Epoch 837/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5703e-05 - val_loss: 0.0013\n",
      "Epoch 838/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5402e-05 - val_loss: 0.0013\n",
      "Epoch 839/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.5106e-05 - val_loss: 0.0013\n",
      "Epoch 840/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.4815e-05 - val_loss: 0.0013\n",
      "Epoch 841/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.4530e-05 - val_loss: 0.0013\n",
      "Epoch 842/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.4249e-05 - val_loss: 0.0013\n",
      "Epoch 843/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.3974e-05 - val_loss: 0.0013\n",
      "Epoch 844/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.3703e-05 - val_loss: 0.0013\n",
      "Epoch 845/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.3438e-05 - val_loss: 0.0013\n",
      "Epoch 846/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.3176e-05 - val_loss: 0.0013\n",
      "Epoch 847/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.2920e-05 - val_loss: 0.0014\n",
      "Epoch 848/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2668e-05 - val_loss: 0.0014\n",
      "Epoch 849/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.2421e-05 - val_loss: 0.0014\n",
      "Epoch 850/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.2178e-05 - val_loss: 0.0014\n",
      "Epoch 851/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.1940e-05 - val_loss: 0.0014\n",
      "Epoch 852/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.1706e-05 - val_loss: 0.0014\n",
      "Epoch 853/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1476e-05 - val_loss: 0.0014\n",
      "Epoch 854/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.1250e-05 - val_loss: 0.0014\n",
      "Epoch 855/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.1028e-05 - val_loss: 0.0014\n",
      "Epoch 856/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.0810e-05 - val_loss: 0.0014\n",
      "Epoch 857/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.0597e-05 - val_loss: 0.0014\n",
      "Epoch 858/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0387e-05 - val_loss: 0.0015\n",
      "Epoch 859/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.0180e-05 - val_loss: 0.0015\n",
      "Epoch 860/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.9978e-05 - val_loss: 0.0015\n",
      "Epoch 861/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.9780e-05 - val_loss: 0.0015\n",
      "Epoch 862/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9585e-05 - val_loss: 0.0015\n",
      "Epoch 863/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9393e-05 - val_loss: 0.0015\n",
      "Epoch 864/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9205e-05 - val_loss: 0.0015\n",
      "Epoch 865/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9021e-05 - val_loss: 0.0015\n",
      "Epoch 866/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.8840e-05 - val_loss: 0.0015\n",
      "Epoch 867/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8662e-05 - val_loss: 0.0015\n",
      "Epoch 868/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.8487e-05 - val_loss: 0.0015\n",
      "Epoch 869/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8316e-05 - val_loss: 0.0016\n",
      "Epoch 870/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.8148e-05 - val_loss: 0.0016\n",
      "Epoch 871/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7983e-05 - val_loss: 0.0016\n",
      "Epoch 872/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7821e-05 - val_loss: 0.0016\n",
      "Epoch 873/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.7662e-05 - val_loss: 0.0016\n",
      "Epoch 874/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.7506e-05 - val_loss: 0.0016\n",
      "Epoch 875/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7353e-05 - val_loss: 0.0016\n",
      "Epoch 876/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7203e-05 - val_loss: 0.0016\n",
      "Epoch 877/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7055e-05 - val_loss: 0.0016\n",
      "Epoch 878/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.6911e-05 - val_loss: 0.0016\n",
      "Epoch 879/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6768e-05 - val_loss: 0.0016\n",
      "Epoch 880/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6629e-05 - val_loss: 0.0016\n",
      "Epoch 881/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.6492e-05 - val_loss: 0.0017\n",
      "Epoch 882/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.6358e-05 - val_loss: 0.0017\n",
      "Epoch 883/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.6227e-05 - val_loss: 0.0017\n",
      "Epoch 884/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.6097e-05 - val_loss: 0.0017\n",
      "Epoch 885/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5971e-05 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.5846e-05 - val_loss: 0.0017\n",
      "Epoch 887/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.5724e-05 - val_loss: 0.0017\n",
      "Epoch 888/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.5605e-05 - val_loss: 0.0017\n",
      "Epoch 889/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5487e-05 - val_loss: 0.0017\n",
      "Epoch 890/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.5372e-05 - val_loss: 0.0017\n",
      "Epoch 891/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5259e-05 - val_loss: 0.0017\n",
      "Epoch 892/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5148e-05 - val_loss: 0.0017\n",
      "Epoch 893/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5039e-05 - val_loss: 0.0017\n",
      "Epoch 894/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.4933e-05 - val_loss: 0.0017\n",
      "Epoch 895/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.4828e-05 - val_loss: 0.0018\n",
      "Epoch 896/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4725e-05 - val_loss: 0.0018\n",
      "Epoch 897/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.4625e-05 - val_loss: 0.0018\n",
      "Epoch 898/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4526e-05 - val_loss: 0.0018\n",
      "Epoch 899/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.4429e-05 - val_loss: 0.0018\n",
      "Epoch 900/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.4334e-05 - val_loss: 0.0018\n",
      "Epoch 901/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4240e-05 - val_loss: 0.0018\n",
      "Epoch 902/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4149e-05 - val_loss: 0.0018\n",
      "Epoch 903/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4059e-05 - val_loss: 0.0018\n",
      "Epoch 904/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.3971e-05 - val_loss: 0.0018\n",
      "Epoch 905/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3885e-05 - val_loss: 0.0018\n",
      "Epoch 906/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.3800e-05 - val_loss: 0.0018\n",
      "Epoch 907/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3717e-05 - val_loss: 0.0018\n",
      "Epoch 908/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.3636e-05 - val_loss: 0.0018\n",
      "Epoch 909/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.3556e-05 - val_loss: 0.0019\n",
      "Epoch 910/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.3478e-05 - val_loss: 0.0019\n",
      "Epoch 911/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3401e-05 - val_loss: 0.0019\n",
      "Epoch 912/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3325e-05 - val_loss: 0.0019\n",
      "Epoch 913/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.3252e-05 - val_loss: 0.0019\n",
      "Epoch 914/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.3179e-05 - val_loss: 0.0019\n",
      "Epoch 915/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3108e-05 - val_loss: 0.0019\n",
      "Epoch 916/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3039e-05 - val_loss: 0.0019\n",
      "Epoch 917/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2970e-05 - val_loss: 0.0019\n",
      "Epoch 918/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.2903e-05 - val_loss: 0.0019\n",
      "Epoch 919/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2837e-05 - val_loss: 0.0019\n",
      "Epoch 920/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2773e-05 - val_loss: 0.0019\n",
      "Epoch 921/1200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.2710e-05 - val_loss: 0.0019\n",
      "Epoch 922/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.2648e-05 - val_loss: 0.0019\n",
      "Epoch 923/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2587e-05 - val_loss: 0.0019\n",
      "Epoch 924/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2528e-05 - val_loss: 0.0019\n",
      "Epoch 925/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2469e-05 - val_loss: 0.0019\n",
      "Epoch 926/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2412e-05 - val_loss: 0.0020\n",
      "Epoch 927/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2356e-05 - val_loss: 0.0020\n",
      "Epoch 928/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.2301e-05 - val_loss: 0.0020\n",
      "Epoch 929/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2247e-05 - val_loss: 0.0020\n",
      "Epoch 930/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2194e-05 - val_loss: 0.0020\n",
      "Epoch 931/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2142e-05 - val_loss: 0.0020\n",
      "Epoch 932/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2091e-05 - val_loss: 0.0020\n",
      "Epoch 933/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.2041e-05 - val_loss: 0.0020\n",
      "Epoch 934/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.1992e-05 - val_loss: 0.0020\n",
      "Epoch 935/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1944e-05 - val_loss: 0.0020\n",
      "Epoch 936/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.1897e-05 - val_loss: 0.0020\n",
      "Epoch 937/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1851e-05 - val_loss: 0.0020\n",
      "Epoch 938/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.1806e-05 - val_loss: 0.0020\n",
      "Epoch 939/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1761e-05 - val_loss: 0.0020\n",
      "Epoch 940/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1718e-05 - val_loss: 0.0020\n",
      "Epoch 941/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1675e-05 - val_loss: 0.0020\n",
      "Epoch 942/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1634e-05 - val_loss: 0.0020\n",
      "Epoch 943/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1593e-05 - val_loss: 0.0020\n",
      "Epoch 944/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1553e-05 - val_loss: 0.0020\n",
      "Epoch 945/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1513e-05 - val_loss: 0.0020\n",
      "Epoch 946/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1474e-05 - val_loss: 0.0021\n",
      "Epoch 947/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1436e-05 - val_loss: 0.0021\n",
      "Epoch 948/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1399e-05 - val_loss: 0.0021\n",
      "Epoch 949/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.1363e-05 - val_loss: 0.0021\n",
      "Epoch 950/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1327e-05 - val_loss: 0.0021\n",
      "Epoch 951/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.1292e-05 - val_loss: 0.0021\n",
      "Epoch 952/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1258e-05 - val_loss: 0.0021\n",
      "Epoch 953/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1224e-05 - val_loss: 0.0021\n",
      "Epoch 954/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1191e-05 - val_loss: 0.0021\n",
      "Epoch 955/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.1159e-05 - val_loss: 0.0021\n",
      "Epoch 956/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1127e-05 - val_loss: 0.0021\n",
      "Epoch 957/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1096e-05 - val_loss: 0.0021\n",
      "Epoch 958/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1065e-05 - val_loss: 0.0021\n",
      "Epoch 959/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1036e-05 - val_loss: 0.0021\n",
      "Epoch 960/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.1006e-05 - val_loss: 0.0021\n",
      "Epoch 961/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0977e-05 - val_loss: 0.0021\n",
      "Epoch 962/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0949e-05 - val_loss: 0.0021\n",
      "Epoch 963/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0921e-05 - val_loss: 0.0021\n",
      "Epoch 964/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0894e-05 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 965/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0867e-05 - val_loss: 0.0021\n",
      "Epoch 966/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0841e-05 - val_loss: 0.0021\n",
      "Epoch 967/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0816e-05 - val_loss: 0.0021\n",
      "Epoch 968/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0791e-05 - val_loss: 0.0021\n",
      "Epoch 969/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0766e-05 - val_loss: 0.0021\n",
      "Epoch 970/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0742e-05 - val_loss: 0.0021\n",
      "Epoch 971/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0718e-05 - val_loss: 0.0021\n",
      "Epoch 972/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0695e-05 - val_loss: 0.0022\n",
      "Epoch 973/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0672e-05 - val_loss: 0.0022\n",
      "Epoch 974/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0650e-05 - val_loss: 0.0022\n",
      "Epoch 975/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0628e-05 - val_loss: 0.0022\n",
      "Epoch 976/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0606e-05 - val_loss: 0.0022\n",
      "Epoch 977/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0585e-05 - val_loss: 0.0022\n",
      "Epoch 978/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0564e-05 - val_loss: 0.0022\n",
      "Epoch 979/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0544e-05 - val_loss: 0.0022\n",
      "Epoch 980/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0524e-05 - val_loss: 0.0022\n",
      "Epoch 981/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0504e-05 - val_loss: 0.0022\n",
      "Epoch 982/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0485e-05 - val_loss: 0.0022\n",
      "Epoch 983/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0466e-05 - val_loss: 0.0022\n",
      "Epoch 984/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0448e-05 - val_loss: 0.0022\n",
      "Epoch 985/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0430e-05 - val_loss: 0.0022\n",
      "Epoch 986/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0412e-05 - val_loss: 0.0022\n",
      "Epoch 987/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0394e-05 - val_loss: 0.0022\n",
      "Epoch 988/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0377e-05 - val_loss: 0.0022\n",
      "Epoch 989/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0360e-05 - val_loss: 0.0022\n",
      "Epoch 990/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0344e-05 - val_loss: 0.0022\n",
      "Epoch 991/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0327e-05 - val_loss: 0.0022\n",
      "Epoch 992/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0312e-05 - val_loss: 0.0022\n",
      "Epoch 993/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0296e-05 - val_loss: 0.0022\n",
      "Epoch 994/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0280e-05 - val_loss: 0.0022\n",
      "Epoch 995/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0265e-05 - val_loss: 0.0022\n",
      "Epoch 996/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0251e-05 - val_loss: 0.0022\n",
      "Epoch 997/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0236e-05 - val_loss: 0.0022\n",
      "Epoch 998/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0222e-05 - val_loss: 0.0022\n",
      "Epoch 999/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0208e-05 - val_loss: 0.0022\n",
      "Epoch 1000/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0194e-05 - val_loss: 0.0022\n",
      "Epoch 1001/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0180e-05 - val_loss: 0.0022\n",
      "Epoch 1002/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0167e-05 - val_loss: 0.0022\n",
      "Epoch 1003/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0154e-05 - val_loss: 0.0022\n",
      "Epoch 1004/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0141e-05 - val_loss: 0.0022\n",
      "Epoch 1005/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0129e-05 - val_loss: 0.0022\n",
      "Epoch 1006/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0116e-05 - val_loss: 0.0022\n",
      "Epoch 1007/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0104e-05 - val_loss: 0.0023\n",
      "Epoch 1008/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0092e-05 - val_loss: 0.0023\n",
      "Epoch 1009/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0080e-05 - val_loss: 0.0023\n",
      "Epoch 1010/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0069e-05 - val_loss: 0.0023\n",
      "Epoch 1011/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0057e-05 - val_loss: 0.0023\n",
      "Epoch 1012/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0046e-05 - val_loss: 0.0023\n",
      "Epoch 1013/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0035e-05 - val_loss: 0.0023\n",
      "Epoch 1014/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0024e-05 - val_loss: 0.0023\n",
      "Epoch 1015/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0014e-05 - val_loss: 0.0023\n",
      "Epoch 1016/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0003e-05 - val_loss: 0.0023\n",
      "Epoch 1017/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9993e-05 - val_loss: 0.0023\n",
      "Epoch 1018/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9983e-05 - val_loss: 0.0023\n",
      "Epoch 1019/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9973e-05 - val_loss: 0.0023\n",
      "Epoch 1020/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9963e-05 - val_loss: 0.0023\n",
      "Epoch 1021/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9953e-05 - val_loss: 0.0023\n",
      "Epoch 1022/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9944e-05 - val_loss: 0.0023\n",
      "Epoch 1023/1200\n",
      "5/5 [==============================] - 0s 749us/step - loss: 1.9935e-05 - val_loss: 0.0023\n",
      "Epoch 1024/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9925e-05 - val_loss: 0.0023\n",
      "Epoch 1025/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9917e-05 - val_loss: 0.0023\n",
      "Epoch 1026/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9908e-05 - val_loss: 0.0023\n",
      "Epoch 1027/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9899e-05 - val_loss: 0.0023\n",
      "Epoch 1028/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9890e-05 - val_loss: 0.0023\n",
      "Epoch 1029/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9882e-05 - val_loss: 0.0023\n",
      "Epoch 1030/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9874e-05 - val_loss: 0.0023\n",
      "Epoch 1031/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9865e-05 - val_loss: 0.0023\n",
      "Epoch 1032/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9857e-05 - val_loss: 0.0023\n",
      "Epoch 1033/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9849e-05 - val_loss: 0.0023\n",
      "Epoch 1034/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9841e-05 - val_loss: 0.0023\n",
      "Epoch 1035/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9833e-05 - val_loss: 0.0023\n",
      "Epoch 1036/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9826e-05 - val_loss: 0.0023\n",
      "Epoch 1037/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9818e-05 - val_loss: 0.0023\n",
      "Epoch 1038/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9811e-05 - val_loss: 0.0023\n",
      "Epoch 1039/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9804e-05 - val_loss: 0.0023\n",
      "Epoch 1040/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9797e-05 - val_loss: 0.0023\n",
      "Epoch 1041/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9789e-05 - val_loss: 0.0023\n",
      "Epoch 1042/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9782e-05 - val_loss: 0.0023\n",
      "Epoch 1043/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9775e-05 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1044/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9769e-05 - val_loss: 0.0023\n",
      "Epoch 1045/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9762e-05 - val_loss: 0.0023\n",
      "Epoch 1046/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9755e-05 - val_loss: 0.0023\n",
      "Epoch 1047/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9748e-05 - val_loss: 0.0023\n",
      "Epoch 1048/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9742e-05 - val_loss: 0.0023\n",
      "Epoch 1049/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9736e-05 - val_loss: 0.0023\n",
      "Epoch 1050/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9729e-05 - val_loss: 0.0023\n",
      "Epoch 1051/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9723e-05 - val_loss: 0.0023\n",
      "Epoch 1052/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9717e-05 - val_loss: 0.0023\n",
      "Epoch 1053/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9711e-05 - val_loss: 0.0023\n",
      "Epoch 1054/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9705e-05 - val_loss: 0.0023\n",
      "Epoch 1055/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9699e-05 - val_loss: 0.0023\n",
      "Epoch 1056/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9693e-05 - val_loss: 0.0023\n",
      "Epoch 1057/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9687e-05 - val_loss: 0.0023\n",
      "Epoch 1058/1200\n",
      "5/5 [==============================] - 0s 757us/step - loss: 1.9682e-05 - val_loss: 0.0023\n",
      "Epoch 1059/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9676e-05 - val_loss: 0.0023\n",
      "Epoch 1060/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9670e-05 - val_loss: 0.0023\n",
      "Epoch 1061/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9665e-05 - val_loss: 0.0023\n",
      "Epoch 1062/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9659e-05 - val_loss: 0.0023\n",
      "Epoch 1063/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9654e-05 - val_loss: 0.0023\n",
      "Epoch 1064/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9649e-05 - val_loss: 0.0023\n",
      "Epoch 1065/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9643e-05 - val_loss: 0.0023\n",
      "Epoch 1066/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9638e-05 - val_loss: 0.0023\n",
      "Epoch 1067/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9633e-05 - val_loss: 0.0023\n",
      "Epoch 1068/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9628e-05 - val_loss: 0.0023\n",
      "Epoch 1069/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9623e-05 - val_loss: 0.0023\n",
      "Epoch 1070/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9618e-05 - val_loss: 0.0023\n",
      "Epoch 1071/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9613e-05 - val_loss: 0.0023\n",
      "Epoch 1072/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9608e-05 - val_loss: 0.0023\n",
      "Epoch 1073/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9603e-05 - val_loss: 0.0023\n",
      "Epoch 1074/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9598e-05 - val_loss: 0.0023\n",
      "Epoch 1075/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9593e-05 - val_loss: 0.0023\n",
      "Epoch 1076/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9588e-05 - val_loss: 0.0023\n",
      "Epoch 1077/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9584e-05 - val_loss: 0.0023\n",
      "Epoch 1078/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9579e-05 - val_loss: 0.0023\n",
      "Epoch 1079/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9574e-05 - val_loss: 0.0023\n",
      "Epoch 1080/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9570e-05 - val_loss: 0.0023\n",
      "Epoch 1081/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9565e-05 - val_loss: 0.0024\n",
      "Epoch 1082/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9561e-05 - val_loss: 0.0024\n",
      "Epoch 1083/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9556e-05 - val_loss: 0.0024\n",
      "Epoch 1084/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9552e-05 - val_loss: 0.0024\n",
      "Epoch 1085/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9548e-05 - val_loss: 0.0024\n",
      "Epoch 1086/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9543e-05 - val_loss: 0.0024\n",
      "Epoch 1087/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9539e-05 - val_loss: 0.0024\n",
      "Epoch 1088/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9535e-05 - val_loss: 0.0024\n",
      "Epoch 1089/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9530e-05 - val_loss: 0.0024\n",
      "Epoch 1090/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9526e-05 - val_loss: 0.0024\n",
      "Epoch 1091/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9522e-05 - val_loss: 0.0024\n",
      "Epoch 1092/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9518e-05 - val_loss: 0.0024\n",
      "Epoch 1093/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9514e-05 - val_loss: 0.0024\n",
      "Epoch 1094/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9510e-05 - val_loss: 0.0024\n",
      "Epoch 1095/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9505e-05 - val_loss: 0.0024\n",
      "Epoch 1096/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9501e-05 - val_loss: 0.0024\n",
      "Epoch 1097/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9497e-05 - val_loss: 0.0024\n",
      "Epoch 1098/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9493e-05 - val_loss: 0.0024\n",
      "Epoch 1099/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9489e-05 - val_loss: 0.0024\n",
      "Epoch 1100/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9485e-05 - val_loss: 0.0024\n",
      "Epoch 1101/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9481e-05 - val_loss: 0.0024\n",
      "Epoch 1102/1200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9477e-05 - val_loss: 0.0024\n",
      "Epoch 1103/1200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9473e-05 - val_loss: 0.0024\n",
      "Epoch 1104/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9470e-05 - val_loss: 0.0024\n",
      "Epoch 1105/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9466e-05 - val_loss: 0.0024\n",
      "Epoch 1106/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9462e-05 - val_loss: 0.0024\n",
      "Epoch 1107/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9458e-05 - val_loss: 0.0024\n",
      "Epoch 1108/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9454e-05 - val_loss: 0.0024\n",
      "Epoch 1109/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9451e-05 - val_loss: 0.0024\n",
      "Epoch 1110/1200\n",
      "5/5 [==============================] - 0s 955us/step - loss: 1.9447e-05 - val_loss: 0.0024\n",
      "Epoch 1111/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9443e-05 - val_loss: 0.0024\n",
      "Epoch 1112/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9439e-05 - val_loss: 0.0024\n",
      "Epoch 1113/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9436e-05 - val_loss: 0.0024\n",
      "Epoch 1114/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9432e-05 - val_loss: 0.0024\n",
      "Epoch 1115/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9428e-05 - val_loss: 0.0024\n",
      "Epoch 1116/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9425e-05 - val_loss: 0.0024\n",
      "Epoch 1117/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9421e-05 - val_loss: 0.0024\n",
      "Epoch 1118/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9417e-05 - val_loss: 0.0024\n",
      "Epoch 1119/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9414e-05 - val_loss: 0.0024\n",
      "Epoch 1120/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9410e-05 - val_loss: 0.0024\n",
      "Epoch 1121/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9407e-05 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1122/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9403e-05 - val_loss: 0.0024\n",
      "Epoch 1123/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9399e-05 - val_loss: 0.0024\n",
      "Epoch 1124/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9396e-05 - val_loss: 0.0024\n",
      "Epoch 1125/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9392e-05 - val_loss: 0.0024\n",
      "Epoch 1126/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9389e-05 - val_loss: 0.0024\n",
      "Epoch 1127/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9385e-05 - val_loss: 0.0024\n",
      "Epoch 1128/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9382e-05 - val_loss: 0.0024\n",
      "Epoch 1129/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9378e-05 - val_loss: 0.0024\n",
      "Epoch 1130/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9375e-05 - val_loss: 0.0024\n",
      "Epoch 1131/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9372e-05 - val_loss: 0.0024\n",
      "Epoch 1132/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9368e-05 - val_loss: 0.0024\n",
      "Epoch 1133/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9364e-05 - val_loss: 0.0024\n",
      "Epoch 1134/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9361e-05 - val_loss: 0.0024\n",
      "Epoch 1135/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9358e-05 - val_loss: 0.0024\n",
      "Epoch 1136/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9354e-05 - val_loss: 0.0024\n",
      "Epoch 1137/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9351e-05 - val_loss: 0.0024\n",
      "Epoch 1138/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9347e-05 - val_loss: 0.0024\n",
      "Epoch 1139/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9344e-05 - val_loss: 0.0024\n",
      "Epoch 1140/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9340e-05 - val_loss: 0.0024\n",
      "Epoch 1141/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9337e-05 - val_loss: 0.0024\n",
      "Epoch 1142/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9334e-05 - val_loss: 0.0024\n",
      "Epoch 1143/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9330e-05 - val_loss: 0.0024\n",
      "Epoch 1144/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9327e-05 - val_loss: 0.0024\n",
      "Epoch 1145/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9324e-05 - val_loss: 0.0024\n",
      "Epoch 1146/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9320e-05 - val_loss: 0.0024\n",
      "Epoch 1147/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9317e-05 - val_loss: 0.0024\n",
      "Epoch 1148/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9314e-05 - val_loss: 0.0024\n",
      "Epoch 1149/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9310e-05 - val_loss: 0.0024\n",
      "Epoch 1150/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9307e-05 - val_loss: 0.0024\n",
      "Epoch 1151/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9304e-05 - val_loss: 0.0024\n",
      "Epoch 1152/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9300e-05 - val_loss: 0.0024\n",
      "Epoch 1153/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9297e-05 - val_loss: 0.0024\n",
      "Epoch 1154/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9294e-05 - val_loss: 0.0024\n",
      "Epoch 1155/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9290e-05 - val_loss: 0.0024\n",
      "Epoch 1156/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9287e-05 - val_loss: 0.0024\n",
      "Epoch 1157/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9284e-05 - val_loss: 0.0024\n",
      "Epoch 1158/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9281e-05 - val_loss: 0.0024\n",
      "Epoch 1159/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9277e-05 - val_loss: 0.0024\n",
      "Epoch 1160/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9274e-05 - val_loss: 0.0024\n",
      "Epoch 1161/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9271e-05 - val_loss: 0.0024\n",
      "Epoch 1162/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9267e-05 - val_loss: 0.0024\n",
      "Epoch 1163/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9264e-05 - val_loss: 0.0024\n",
      "Epoch 1164/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9261e-05 - val_loss: 0.0024\n",
      "Epoch 1165/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9258e-05 - val_loss: 0.0024\n",
      "Epoch 1166/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9254e-05 - val_loss: 0.0024\n",
      "Epoch 1167/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9251e-05 - val_loss: 0.0024\n",
      "Epoch 1168/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9248e-05 - val_loss: 0.0024\n",
      "Epoch 1169/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9245e-05 - val_loss: 0.0024\n",
      "Epoch 1170/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9241e-05 - val_loss: 0.0024\n",
      "Epoch 1171/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9238e-05 - val_loss: 0.0024\n",
      "Epoch 1172/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9235e-05 - val_loss: 0.0024\n",
      "Epoch 1173/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9232e-05 - val_loss: 0.0024\n",
      "Epoch 1174/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9228e-05 - val_loss: 0.0024\n",
      "Epoch 1175/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9225e-05 - val_loss: 0.0024\n",
      "Epoch 1176/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9222e-05 - val_loss: 0.0024\n",
      "Epoch 1177/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9219e-05 - val_loss: 0.0024\n",
      "Epoch 1178/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9216e-05 - val_loss: 0.0024\n",
      "Epoch 1179/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9212e-05 - val_loss: 0.0024\n",
      "Epoch 1180/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9209e-05 - val_loss: 0.0024\n",
      "Epoch 1181/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9206e-05 - val_loss: 0.0024\n",
      "Epoch 1182/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9203e-05 - val_loss: 0.0024\n",
      "Epoch 1183/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9199e-05 - val_loss: 0.0024\n",
      "Epoch 1184/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9196e-05 - val_loss: 0.0024\n",
      "Epoch 1185/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9193e-05 - val_loss: 0.0024\n",
      "Epoch 1186/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9190e-05 - val_loss: 0.0024\n",
      "Epoch 1187/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9187e-05 - val_loss: 0.0024\n",
      "Epoch 1188/1200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9183e-05 - val_loss: 0.0024\n",
      "Epoch 1189/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9180e-05 - val_loss: 0.0024\n",
      "Epoch 1190/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9177e-05 - val_loss: 0.0024\n",
      "Epoch 1191/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9174e-05 - val_loss: 0.0024\n",
      "Epoch 1192/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9170e-05 - val_loss: 0.0024\n",
      "Epoch 1193/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9167e-05 - val_loss: 0.0024\n",
      "Epoch 1194/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9164e-05 - val_loss: 0.0024\n",
      "Epoch 1195/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9161e-05 - val_loss: 0.0024\n",
      "Epoch 1196/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9158e-05 - val_loss: 0.0024\n",
      "Epoch 1197/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9154e-05 - val_loss: 0.0024\n",
      "Epoch 1198/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9151e-05 - val_loss: 0.0024\n",
      "Epoch 1199/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9148e-05 - val_loss: 0.0024\n",
      "Epoch 1200/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9145e-05 - val_loss: 0.0024\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=1200, validation_data=(valX, valY), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example creates a plot showing the characteristic inflection point in validation loss of an overfit model.\n",
    "\n",
    "This may be a sign of too many training epochs.\n",
    "\n",
    "In this case, the model training could be stopped at the inflection point. Alternately, the number of training examples could be increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8VdW58PHfk5mEkECYEyChoDJP\nAVEUtajFodoqrVitQ63e2npbe9vbantvB9/2/dj3ttYOWi9VW2dE1BbrbMWpKhKQedDIICEMIUCA\nAJnO8/6xVvAQT5IDyck+J3m+n8/+nL3XXnufZx8O58lea++1RVUxxhhjjldS0AEYY4xJbJZIjDHG\ntIklEmOMMW1iicQYY0ybWCIxxhjTJpZIjDHGtIklEhMYEfmriPwiyrqbROTsGMZyhYi8FKv9x5KI\n/ExEHvbzg0XkgIgkt1b3ON9rtYicebzbt7Df10Tk6+29X9MxUoIOwJi2EpG/AmWq+l/Huw9VfQR4\npN2CCoiqfgx0b499RfpcVXVUe+zbdC52RmI6PRGxP5iMiSFLJKZFvknpP0VkhYhUi8h9ItJPRJ4X\nkf0i8oqI9Ayrf5Fv/tjrmytGhK2bICJL/XaPAxlN3utCEVnmt31bRMZGEd8NwBXAD3yTzjNhcf9Q\nRFYA1SKSIiK3iMhH/v3XiMgXw/ZzjYi8FbasIvINEflQRPaIyF0iIhHef6CIHBKRXk2Oc5eIpIrI\nMBF5XUSqfNnjzRzHCyJyU5Oy5SJyiZ//nYhsEZF9IrJERE5vZj+FPvYUv1zk33+/iLwM9G5S/wkR\n2e7je0NERkXxuZ7t59NF5E4RKffTnSKS7tedKSJlIvI9EdkpIttE5NrI/4qfOoYkEfkvEdnst31Q\nRHL8ugwReVhEKv33ZLGI9PPrrhGRDf5YN4rIFdG8n2kHqmqTTc1OwCbgXaAfkA/sBJYCE4B04FXg\np77uCUA1cA6QCvwAKAXS/LQZ+K5fNwuoA37ht53o930ykAxc7d87PSyOs5uJ8a+N+2kS9zJgENDN\nl30JGIj7A+oyH+sAv+4a4K2w7RX4B5ALDAYqgJnNvP+rwPVhy/8D3OPnHwN+7N8zAzitmX1cBfwr\nbHkksDfs+K8E8nDN0d8DtgMZft3PgIf9fKGPPcUvvwPc4f+tpgP7G+v69V8Dsv36O4FlUXyuZ/v5\n2/x3oy/QB3gb+D9+3ZlAva+TCpwPHAR6NnP8rwFfD4upFBiKa6Z7CnjIr/s34Bkg039PJgE9gCxg\nH3CirzcAGBX0/5+uMtkZiYnGH1R1h6puBd4EFqnq+6paAzyNSyrgfpyfVdWXVbUO+DXQDTgVmIr7\nQblTVetUdT6wOOw9rgf+V1UXqWqDqj4A1PjtjtfvVXWLqh4CUNUnVLVcVUOq+jjwITClhe1vV9W9\n6vodFgLjm6n3KHA5gD9rme3LwCXLIcBAVT2sqm9F3gVPA+NFZIhfvgJ4yn/GqOrDqlqpqvWq+hvc\nD/+JLR28iAwGJgP/rao1qvoG7kf4CFW9X1X3+/f5GTCu8a//KFwB3KaqO1W1Avg58NWw9XV+fZ2q\nPgccaC3msP3eoaobVPUAcCsw259l1eES6jD/PVmiqvv8diFgtIh0U9Vtqro6yuMwbWSJxERjR9j8\noQjLjZ27A3FnHQCoagjYgjuTGQhsVdXwUUI3h80PAb7nmyv2ishe3NnEwDbEvSV8QUSuCms62wuM\npklTTxPbw+YP0nwn9nzgFBEZiPurX3EJF9xZmQDv+Sa/r0XagaruB57FJSH865HOf99EtNY3Qe0F\nclqJHdxnt0dVq8PKjnzmIpIsIrf75r59uLMNothv+P7D/w03c/S/V6Wq1octt/QZtrbfFNxZ8UPA\ni8Bc35z2/0Qk1R/jZcA3gG0i8qyInBTlcZg2skRi2lM5LiEAR/46HwRsBbYB+U36GQaHzW8Bfqmq\nuWFTpqo+FsX7NjeE9ZFy/5f+n4GbgDxVzQVW4X7k20RV9wIvAV8GvgI81pgwVXW7ql6vqgNxzTJ3\ni8iwZnb1GHC5iJyCO5Nb6GM/Hfih339PH3tVFLFvA3qKSFZYWfhn/hXgYuBsXGIq9OWN+21taPCj\n/r39vstb2SYakfZbD+zwZzc/V9WRuDPdC3HNgqjqi6p6Dq5Zax3u39t0AEskpj3NAy4QkRkikopr\ny6/BtZ2/g/sx+Lbv+L6Eo5uV/gx8Q0ROFidLRC4Qkewo3ncHrj29JVm4H8YKAN/xO/pYDq4Vj+J+\n0C7lk2YtRORLIlLgF/f4GBqa2cdzuB/Q24DH/RkduD6Meh97ioj8BNcv0CJV3QyUAD8XkTQROQ34\nfFiVbNy/TyWuz+H/NtlFa5/rY8B/iUgfEekN/AQ47ntUmuz3u/5Cge4+rsdVtV5EzhKRMeLuk9mH\na+pqEHcByEU+adbgmtGa+5xNO7NEYtqNqq7HdQr/AdiF+9H6vKrWqmotcAmuU3sPrhniqbBtS3D9\nJH/060t93WjcB4z0TVZ/aya2NcBvcAltBzAG+NexHWGLFgDDcX81Lw8rnwwsEpEDvs53VHVjMzHW\n4D6TswlLRrimnOeBD3DNPIdp0mzXgq/gLmDYDfwUeDBs3YN+f1uBNbiO83Ctfa6/wCWqFcBK3EUY\nUd1g2or7cU1YbwAbccf7735df1xT4j5gLfA6Lnkl4f5wKccd6xnAN9shFhMFObrJ2hhjjDk2dkZi\njDGmTSyRGGOMaRNLJMYYY9rEEokxxpg26RKD2fXu3VsLCwuDDsMYYxLKkiVLdqlqn9bqdYlEUlhY\nSElJSdBhGGNMQhGRza3XsqYtY4wxbWSJxBhjTJtYIjHGGNMmXaKPxBjTedTV1VFWVsbhw4eDDqXT\nyMjIoKCggNTU1OPa3hKJMSahlJWVkZ2dTWFhIfLph1aaY6SqVFZWUlZWRlFR0XHtw5q2jDEJ5fDh\nw+Tl5VkSaSciQl5eXpvO8GKaSERkpoisF5FSEbklwvp0EXncr18kIoW+PE9EFvpnRf8xrH6mf2DN\nOv+QoNtjGb8xJj5ZEmlfbf08Y5ZI/PMC7gLOwz1/+nIRGdmk2nW4J7gNA34L/MqXHwb+G/h+hF3/\nWlVPwj3edZqInBeL+AF478+wcn7Mdm+MMZ1BLM9IpgCl/rnLtcBc3NPYwl0MPODn5wMzRERUtdo/\n2/qocy1VPaiqC/18Le75BwXEyvsPuckYY7y9e/dy9913H/N2559/Pnv37o1BRMGLZSLJ5+iH75T5\nsoh1/LOdq4C8aHYuIrm4Byf9s5n1N4hIiYiUVFRUHGPoXv8xsH0V2DNbjDFec4mkoaHlBzI+99xz\n5ObmxiqsQMUykURqdGv6ixxNnU/vWCQF9zjO36vqhkh1VHWOqharanGfPq0OFRNZ/7FwcBfs3358\n2xtjOp1bbrmFjz76iPHjxzN58mTOOussvvKVrzBmzBgAvvCFLzBp0iRGjRrFnDlzjmxXWFjIrl27\n2LRpEyNGjOD6669n1KhRnHvuuRw6dCiow2kXsbz8twwYFLZcgHsMZqQ6ZT455OAek9maOcCHqnpn\newTarP7ui8H2ldBjQEzfyhhz7H7+zGrWlO9r132OHNiDn35+VLPrb7/9dlatWsWyZct47bXXuOCC\nC1i1atWRS2fvv/9+evXqxaFDh5g8eTKXXnopeXlHN7R8+OGHPPbYY/z5z3/my1/+Mk8++SRXXnll\nux5HR4rlGcliYLiIFIlIGjAb98zqcAuAq/38LOBVbeXZvyLyC1zCubmd4/20fv7LtH1FzN/KGJOY\npkyZctT9F7///e8ZN24cU6dOZcuWLXz44Yef2qaoqIjx48cDMGnSJDZt2tRR4cZEzM5IVLVeRG4C\nXgSSgftVdbWI3AaUqOoC4D7gIREpxZ2JzG7cXkQ2AT2ANBH5AnAusA/4MbAOWOovWfujqt4bk4PI\nyIHcIe6MxBgTd1o6c+goWVlZR+Zfe+01XnnlFd555x0yMzM588wzI96fkZ6efmQ+OTnZmrZaoqrP\nAc81KftJ2Pxh4EvNbFvYzG479gLy/mNgx6oOfUtjTPzKzs5m//79EddVVVXRs2dPMjMzWbduHe++\n+24HRxcMGyKlNf3HwrpnoeYApHcPOhpjTMDy8vKYNm0ao0ePplu3bvTr1+/IupkzZ3LPPfcwduxY\nTjzxRKZOnRpgpB3HEklr+o8BFHaugUFTgo7GGBMHHn300Yjl6enpPP/88xHXNfaD9O7dm1WrPmnl\n+P73I913nVhsrK3W9B/tXq3D3RhjIrJE0pqcQa7Tfbv1kxhjTCSWSFoj4vpJ7MotY4yJyBJJNPqP\ngR2rIdTyEAjGGNMVWSKJRv8xUH8IKj8KOhJjjIk7lkii0c93uO+w5i1jjGnKEkk0+pwESanWT2KM\nOWbdu7v7z8rLy5k1a1bEOmeeeSYlJSUt7ufOO+/k4MGDR5bjaVh6SyTRSElzycQSiTHmOA0cOJD5\n84//QXlNE0k8DUtviSRa/cdYIjHG8MMf/vCo55H87Gc/4+c//zkzZsxg4sSJjBkzhr///e+f2m7T\npk2MHu2ayQ8dOsTs2bMZO3Ysl1122VFjbd14440UFxczatQofvrTnwJuIMjy8nLOOusszjrrLOCT\nYekB7rjjDkaPHs3o0aO58847j7xfRw1Xb3e2R6v/aFj+KBzYCd37Bh2NMQbg+Vva/w+8/mPgvNub\nXT179mxuvvlmvvnNbwIwb948XnjhBb773e/So0cPdu3axdSpU7nooouafRb6n/70JzIzM1mxYgUr\nVqxg4sSJR9b98pe/pFevXjQ0NDBjxgxWrFjBt7/9be644w4WLlxI7969j9rXkiVL+Mtf/sKiRYtQ\nVU4++WTOOOMMevbs2WHD1dsZSbTCn01ijOmyJkyYwM6dOykvL2f58uX07NmTAQMG8KMf/YixY8dy\n9tlns3XrVnbs2NHsPt54440jP+hjx45l7NixR9bNmzePiRMnMmHCBFavXs2aNWtajOett97ii1/8\nIllZWXTv3p1LLrmEN998E+i44ertjCRajVdubV8Jw2YEG4sxxmnhzCGWZs2axfz589m+fTuzZ8/m\nkUceoaKigiVLlpCamkphYWHE4ePDRTpb2bhxI7/+9a9ZvHgxPXv25Jprrml1Py09wqmjhqu3M5Jo\nZfZyw6XYmFvGdHmzZ89m7ty5zJ8/n1mzZlFVVUXfvn1JTU1l4cKFbN68ucXtp0+fziOPPALAqlWr\nWLHC/a7s27ePrKwscnJy2LFjx1EDQDY3fP306dP529/+xsGDB6murubpp5/m9NNPb8ejbZ2dkRyL\nAeOgfFnQURhjAjZq1Cj2799Pfn4+AwYM4IorruDzn/88xcXFjB8/npNOOqnF7W+88UauvfZaxo4d\ny/jx45kyxY0sPm7cOCZMmMCoUaMYOnQo06ZNO7LNDTfcwHnnnceAAQNYuHDhkfKJEydyzTXXHNnH\n17/+dSZMmNChT12UVp5s2ykUFxdra9doR+X1/4GFv4BbPnYDORpjOtzatWsZMWJE0GF0OpE+VxFZ\noqrFrW1rTVvHYqDrtGKbNW8ZY0wjSyTHYkBjIlkebBzGGBNHLJEci+59oEc+bLN+EmOC1BWa5DtS\nWz9PSyTHasB463A3JkAZGRlUVlZaMmknqkplZSUZGRnHvQ+7autYDRwP65+Dmv2Qnh10NMZ0OQUF\nBZSVlVFRURF0KJ1GRkYGBQUFx729JZJjNWAcoK7DvXBaq9WNMe0rNTWVoqKioMMwYWLatCUiM0Vk\nvYiUisgtEdani8jjfv0iESn05XkislBEDojIH5tsM0lEVvptfi/NDWYTK9bhbowxR4lZIhGRZOAu\n4DxgJHC5iIxsUu06YI+qDgN+C/zKlx8G/hv4foRd/wm4ARjup5ntH30LsvtB9gDrcDfGGC+WZyRT\ngFJV3aCqtcBc4OImdS4GHvDz84EZIiKqWq2qb+ESyhEiMgDooarvqOtpexD4QgyPITLrcDfGmCNi\nmUjygS1hy2W+LGIdVa0HqoC8VvZZ1so+Y2/geNj1AdQc6PC3NsaYeBPLRBKp76Lp9XrR1Dmu+iJy\ng4iUiEhJu1/dMWC8e1sbUt4YY2KaSMqAQWHLBUB5c3VEJAXIAXa3ss/wa9Qi7RMAVZ2jqsWqWtyn\nT59jDL0VA8a5V+snMcaYmCaSxcBwESkSkTRgNrCgSZ0FwNV+fhbwqrZwl5GqbgP2i8hUf7XWVcCn\nn2kZaz0GQPd+duWWMcYQw/tIVLVeRG4CXgSSgftVdbWI3AaUqOoC4D7gIREpxZ2JzG7cXkQ2AT2A\nNBH5AnCuqq4BbgT+CnQDnvdTx7MOd2OMAWJ8Q6KqPgc816TsJ2Hzh4EvNbNtYTPlJcDo9ovyOA0c\nD6UvQ201pGUFHY0xxgTGxto6XgMngoZsSHljTJdnieR45U90r1uXBBuHMcYEzBLJ8ereF3IGWyIx\nxnR5lkjaIn+iJRJjTJdniaQt8ifB3s1QvSvoSIwxJjCWSNoif5J7tbMSY0wXZomkLQaMA0myRGKM\n6dIskbRFenfoM8ISiTGmS7NE0laNHe72/GhjTBdliaSt8ifBoT2wZ2PQkRhjTCAskbTVkQ73pcHG\nYYwxAbFE0lZ9R0JKN+snMcZ0WZZI2io5xQ3gaInEGNNFWSJpD/mT3LNJGuqCjsQYYzqcJZL2kD8R\n6g/DzjVBR2KMMR3OEkl7sDvcjTFdmCWS9pA7BDJ7w5bFQUdijDEdzhJJexCBQVOg7L2gIzHGmA5n\niaS9DJoClaVQXRl0JMYY06EskbSXginutcyat4wxXYslkvYycAIkpcCWRUFHYowxHcoSSXtJy4T+\nY2GL9ZMYY7oWSyTtadDJ7hJguzHRGNOFWCJpT4OmQP0h2LEq6EiMMabDxDSRiMhMEVkvIqUickuE\n9eki8rhfv0hECsPW3erL14vI58LKvysiq0VklYg8JiIZsTyGYzLId7hb85YxpguJWSIRkWTgLuA8\nYCRwuYiMbFLtOmCPqg4Dfgv8ym87EpgNjAJmAneLSLKI5APfBopVdTSQ7OvFh5wC6JFvHe7GmC4l\nlmckU4BSVd2gqrXAXODiJnUuBh7w8/OBGSIivnyuqtao6kag1O8PIAXoJiIpQCZQHsNjOHaDptgZ\niTGmS4llIskHtoQtl/myiHVUtR6oAvKa21ZVtwK/Bj4GtgFVqvpSTKI/XoNOhqotsC++8psxxsRK\nLBOJRChr+mDz5upELBeRnrizlSJgIJAlIldGfHORG0SkRERKKioqjiHsNiqwfhJjTNcSy0RSBgwK\nWy7g081QR+r4pqocYHcL254NbFTVClWtA54CTo305qo6R1WLVbW4T58+7XA4Ueo/BlIyLJEYY7qM\nWCaSxcBwESkSkTRcp/iCJnUWAFf7+VnAq6qqvny2v6qrCBgOvIdr0poqIpm+L2UGsDaGx3DsUtJg\n4ETrcDfGdBkxSyS+z+Mm4EXcj/08VV0tIreJyEW+2n1AnoiUAv8B3OK3XQ3MA9YALwDfUtUGVV2E\n65RfCqz08c+J1TEct0FT3BMT6w4FHYkxxsScuBOAzq24uFhLSko67g3XvwCPXQbXPAuFp3Xc+xpj\nTDsSkSWqWtxaPbuzPRYGnwwIbH476EiMMSbmLJHEQree0G80bP5X0JEYY0zMWSKJlSGnuiu3bABH\nY0wnZ4kkVoacCnUHXae7McZ0YpZIYmWIv73FmreMMZ2cJZJY6d4X8oZZh7sxptOzRBJLQ06Fze9A\nqCHoSIwxJmYskcTSkGlQUwU71wQdiTHGxIwlklg60k9izVvGmM7LEkks5Q6GnEGWSIwxnZolklgb\ncqpLJF1gKBpjTNdkiSTWhpwK1Tuh8qOgIzHGmJiwRBJrgxv7Sd4KNg5jjIkRSySx1ns4ZPWFTZZI\njDGdkyWSWBOBoumw8Q3rJzHGdEqWSDpC0XQ4sAMq1gcdiTHGtDtLJB1h6BnudePrwcZhjDExYImk\nI/QshNwhrnnLGGM6GUskHaVoOmx608bdMsZ0OpZIOsrQM+FwFWxbFnQkxhjTriyRdJSi6e7VmreM\nMZ1MVIlERL4jIj3EuU9ElorIubEOrlPp3hf6joQN1uFujOlcoj0j+Zqq7gPOBfoA1wK3xyyqzqpo\nOnz8LtTXBB2JMca0m2gTifjX84G/qOrysDITraIzoP4QlC0OOhJjjGk30SaSJSLyEi6RvCgi2UCo\ntY1EZKaIrBeRUhG5JcL6dBF53K9fJCKFYetu9eXrReRzYeW5IjJfRNaJyFoROSXKYwhe4TSQJGve\nMsZ0KtEmkuuAW4DJqnoQSMU1bzVLRJKBu4DzgJHA5SIyMsJ+96jqMOC3wK/8tiOB2cAoYCZwt98f\nwO+AF1T1JGAcsDbKYwheRg4MnGAd7saYTiXaRHIKsF5V94rIlcB/AVWtbDMFKFXVDapaC8wFLm5S\n52LgAT8/H5ghIuLL56pqjapuBEqBKSLSA5gO3AegqrWqujfKY4gPRWfA1hI4vC/oSIwxpl1Em0j+\nBBwUkXHAD4DNwIOtbJMPbAlbLvNlEeuoaj0uOeW1sO1QoAL4i4i8LyL3ikhWpDcXkRtEpERESioq\nKqI4xA4ybAaE6t3NicYY0wlEm0jqVVVxZwq/U9XfAdmtbBOpM77p8LfN1WmuPAWYCPxJVScA1bgm\nt09XVp2jqsWqWtynT59WQu1ABVMgLRtKXwk6EmOMaRfRJpL9InIr8FXgWd9fkdrKNmXAoLDlAqC8\nuToikgLkALtb2LYMKFPVRb58Pi6xJI6UNHcZcOkrNqy8MaZTiDaRXAbU4O4n2Y5rZvqfVrZZDAwX\nkSIRScN1ni9oUmcBcLWfnwW86s98FgCz/VVdRcBw4D3/3ltE5ES/zQxgTZTHED+GzYC9H0NladCR\nGGNMm6VEU0lVt4vII8BkEbkQ96PeYh+JqtaLyE3Ai0AycL+qrhaR24ASVV2A6zR/SERKcWcis/22\nq0VkHi5J1APfUtXG0Q7/HXjEJ6cNtHL1WFwaNsO9lr7inqBojDEJTDSK5hUR+TLuDOQ1XP/F6cB/\nqur8mEbXToqLi7WkpCToMI72h2I3vPyVCfERGmO6IBFZoqrFrdWL6owE+DHuHpKdfud9gFdwfRTm\neAybAUsegLpDkNot6GiMMea4RdtHktSYRLzKY9jWRDLsbDdcyua3g47EGGPaJNpk8IKIvCgi14jI\nNcCzwHOxC6sLGDINktOh9J9BR2KMMW0SVSJR1f8E5gBjccOSzFHVH8YysE4vLROGnGr3kxhjEl60\nfSSo6pPAkzGMpesZdja89GPYsxl6Dgk6GmOMOS4tnpGIyH4R2Rdh2i8iNlhUW50w071+8EKwcRhj\nTBu0mEhUNVtVe0SYslW1R0cF2Wn1HgZ5w2H980FHYowxx82uvAraiTNh01s2GrAxJmFZIgnaCedB\nqA4+ejXoSIwx5rhYIgnaoJMhI9f6SYwxCcsSSdCSU2D4ufDhSxBqaL2+McbEGUsk8eDEmXCwEsoW\nBx2JMcYcM0sk8WDY2ZCUYldvGWMSkiWSeJCR4+5yt0RijElAlkjixYnnw671UPlR0JEYY8wxsUQS\nL066wL2ubfoQSWOMiW+WSOJF7mAYOAHW/D3oSIwx5phYIoknIy+G8vfd89yNMSZBWCKJJyMucq9r\nnwk2DmOMOQaWSOJJ3meg32hYY/0kxpjEYYkk3oy8GLYsgn3bgo7EGGOiYokk3oy4CFBY94+gIzHG\nmKhYIok3fU+C3ifY1VvGmIRhiSQejbgINv8LDlQEHYkxxrQqpolERGaKyHoRKRWRWyKsTxeRx/36\nRSJSGLbuVl++XkQ+12S7ZBF5X0Q6Z/vP6EtAQ7Dmb0FHYowxrYpZIhGRZOAu4DxgJHC5iIxsUu06\nYI+qDgN+C/zKbzsSmA2MAmYCd/v9NfoOsDZWsQeu3yjoOxJWzg86EmOMaVUsz0imAKWqukFVa4G5\nwMVN6lwMPODn5wMzRER8+VxVrVHVjUCp3x8iUgBcANwbw9iDN2YWbHkX9mwOOhJjjGlRLBNJPrAl\nbLnMl0Wso6r1QBWQ18q2dwI/AEItvbmI3CAiJSJSUlGRgH0No2e511V2VmKMiW+xTCQSoUyjrBOx\nXEQuBHaq6pLW3lxV56hqsaoW9+nTp/Vo403PITBoqjVvGWPiXiwTSRkwKGy5AChvro6IpAA5wO4W\ntp0GXCQim3BNZZ8VkYdjEXxcGDMLdq6BHauDjsQYY5oVy0SyGBguIkUikobrPG869scC4Go/Pwt4\nVVXVl8/2V3UVAcOB91T1VlUtUNVCv79XVfXKGB5DsEZ9ESQZVj4RdCTGGNOsmCUS3+dxE/Ai7gqr\neaq6WkRuExE/OiH3AXkiUgr8B3CL33Y1MA9YA7wAfEtVG2IVa9zK6g2f+SysfBJCLXYJGWNMYMSd\nAHRuxcXFWlJSEnQYx2f54/D0DXDNc1A4LehojDFdiIgsUdXi1urZne3xbsSFkJYN73feriBjTGKz\nRBLv0rJgzKXuLvfD+4KOxhhjPsUSSSKY8FWoOwirnw46EmOM+RRLJIkgfxL0OQnefyjoSIwx5lMs\nkSQCEZhwJZQthp3rgo7GGGOOYokkUYydDUkpsMw63Y0x8cUSSaLo3gdOmAnL50JDXdDRGGPMEZZI\nEsmEr0J1Bax7NuhIjDHmCEskiWT4OZAzGBZ37hH0jTGJxRJJIklKhslfg01vws7O+1wvY0xisUSS\naCZcBcnp8N6fg47EGGMASySJJysPRl/qOt0PVwUdjTHGWCJJSFO+DnXVLpkYY0zALJEkovxJbnrv\nz9AFRm82xsQ3SySJavL1UPkhfPRq0JEYY7o4SySJavQl0L0/vP2HoCMxxnRxlkgSVUo6nPxvsGEh\nbFsedDTGmC7MEkkiK/4apHW3sxJjTKAskSSybrkw6RpY9RTs/TjoaIwxXZQlkkQ39UY3zPw7dwcd\niTGmi0oJOgDTRjkFMHoWLH0ATv+eGyXYGNM8VWiodU8drTsM9YfciNoNdRCqg4Z6t75xPlTnlhvq\nIFTv69aChty+NARoFMt+alwHIEmAuFdpuiwtLMsny41lSckgyf7Vlyclw0kXutcYskTSGZz+PVg5\nD97+PZz7f4KOxpj2pQq11XBstwZ1AAAW9ElEQVRoN9Tsh8P73GvNPjcdtbzfTbXVUHfIJYm6JlP9\noU9+yLuCH++wRGKi0OcEd1ay+F449dt2VmLiX30N7N8O+7e5qXoXHNwNByvh4C7/WgnV/rWhpuX9\nSRKk94CMHpCWDWlZkJrh+hFTu0FKN/faOKVkQGqmq5OSAclpkJwKSal+PsXPp4aVp7qHyzXWleSw\nMwWhxTOJputEXNwazZlM+DLNrA9BqAG0AUIh99pYlpwWq3/FIyyRdBbT/xNWzbezEhO8hjqoKoO9\nm2HPJthX7qbwxHGwMvK2GTmQmeemHgXQfxxk9nLL3Xq6RJHew9VLz/4keaRmfvLjnEhEXEJKcDFN\nJCIyE/gdkAzcq6q3N1mfDjwITAIqgctUdZNfdytwHdAAfFtVXxSRQb5+fyAEzFHV38XyGBKGnZWY\njlRbDZWlsOtD2L0R9m6CPZvdtG+r+4v4CIHufSG7P+QMgkFTIHtA2NTfre/W0/2lbxJOzBKJiCQD\ndwHnAGXAYhFZoKprwqpdB+xR1WEiMhv4FXCZiIwEZgOjgIHAKyJyAlAPfE9Vl4pINrBERF5uss+u\n64wfuLOSf90Jn/tl0NGYzqC6EirWwa71LmlU+NeqJpebd+8HuUNg8MnQs9DN9xziXnsMtATRycXy\njGQKUKqqGwBEZC5wMRD+o38x8DM/Px/4o4iIL5+rqjXARhEpBaao6jvANgBV3S8ia4H8JvvsunoP\nh3FfgffmwJTr3X9oY6IRCrmziu0rP5m2rYD95Z/USc1037HBJ0Pvq9x87xOgV5HrdzBdViwTST6w\nJWy5DDi5uTqqWi8iVUCeL3+3ybb54RuKSCEwAVgU6c1F5AbgBoDBgwcf5yEkoLN+BKuehFd/AZfa\nI3lNM/aVQ9li2PIebF0KO1a5q57Atdn3PgGKTod+o6HfSLfcowCS7NYz82mxTCSRer6ajnneXJ0W\ntxWR7sCTwM2qui/Sm6vqHGAOQHFxcdcZaz0nH075Jrz5G5j6TcifGHREJmj1tVD+vkscjdO+rW5d\nchoMGAdjvwz9x0D/sdB3hJ1hmGMSy0RSBgwKWy4AypupUyYiKUAOsLulbUUkFZdEHlHVp2ITeoKb\ndjMs+Su8/BO4+pnEvJrFHL/GxLHpTTd9vMjdOwGQOxgGT4WCKVAwGfqPdgOAGtMGsUwki4HhIlIE\nbMV1nn+lSZ0FwNXAO8As4FVVVRFZADwqInfgOtuHA+/5/pP7gLWqekcMY09sGT3gzFvhue/D2mdg\n5EVBR2RiKRSC7Svgo3/Cprfg43fdXdvgmqYmXQ2Fp7nkkd0v2FhNpxSzROL7PG4CXsRd/nu/qq4W\nkduAElVdgEsKD/nO9N24ZIOvNw/XiV4PfEtVG0TkNOCrwEoRWebf6keq+lyMjgFJ1L/mJ13rzkpe\nuBWGzXA3aJnO49Ae91CzD1+B0legeqcr7zsSJlwJhafDkGmQlRdsnKZLEO0Cj2otLi7WkpKSY97u\n5rnv0ysrnX87Yyj9emTEILIY2/wO/GUmnPYfcPZPg47GtIUq7FwL656F0pddP4eGICPX/aEw7Bz4\nzGftjMO0KxFZoqrFrdWzO9ub0RBSUpOTeOCdTTy8aDOXTx7EN878DANyEqgTcsgp7nLgt/8A4y53\nNy2axBEKwdYlsO4Z10S5e4MrHzgBTv8+DD8H8ifFfBwlY1pjZySt2FxZzd0LP+LJpWUkifDlyQXc\neOYw8nMTJKEcqIA/TIIBY+GqBXb5ZrwLNbh+jrXPwLp/uOFEklKgaLobxfWkC9yd4MZ0gGjPSCyR\nRGnL7oP86fWPeKLE3Roza1IBN0z/DEW9E6DvYclf4ZnvwPm/djcqmvii6u7lWPmEuweoeqcbZHDY\nDBhxEZxwrhs+xJgOZokkTHskkkblew9xz+sfMXfxFuoaQpw7sh83TB/KpCG92mX/MaEKD1/iLgP9\n5tt2x3u8qPjAJY+VT8Ceje6ejhM+58ZMG34upGUGHaHp4iyRhGnPRNJo5/7DPPj2Zh56dzNVh+qY\nNKQn158+lHNG9iM5KQ6v9Koqg7tPcTefWRNXcKp3wYp5sGIubFvuhhQvmg5jvuSarrrlBh2hMUdY\nIgkTi0TS6GBtPfMWb+HetzZStucQRb2zuHZaIZdMLKB7epxdy7D0QVjw73DuL+HUm4KOpusINbhL\ndZc+COufd0/cGzgBxl4Go75ofR4mblkiCRPLRNKoviHEi6t3MOeNj1heVkVWWjKXTCzgqlOGMLxf\ndkzfO2qq8PiV8MGL8LUXoWBS0BF1bpUfwbJHYNljbvDDzDx39dz4K9z4VcbEOUskYToikTRSVZZt\n2ctD72zmHyu2UdsQYurQXlx1SiHnjOxHanLATUqH9sA9091oZv/2pjWltLe6w7Dmb7D0Idj8lmu6\nGnaOu0nwhJmQEvun1RnTXiyRhOnIRBKu8kAN80rKePjdzWzde4h+PdK5dGIBXyoeFOzVXmUlcP/n\n3A/blx+y/pL2sGczlNwP7z/knv7Xa6hLHuMud8/jMCYBWSIJE1QiadQQUhau28kjizbz+gcVhBQm\nF/bkS5MGcf7YAcH0pbxzF7z4Izjjh27oeXPsQiHX97H4z665UAROPN9dYl10hg2WaRKeJZIwQSeS\ncDv2HeappVt5YskWNlRUk5mWzPljBnDpxAKmFPXquCu+VOHvN8Gyh+HS+2DMrI55387g4G7X97H4\nPnfZblZfNzDipGsgpyDo6IxpN5ZIwsRTImmkqiz9eA9PlJTxjxXbOFBTT9/sdC4YO4ALxw5k4uDc\n2A8YWV8LD17shuG45lkYNDm275foti51yWPVfKg/DINPhcnXuZsGre/DdEKWSMLEYyIJd6i2gX+u\n28Ezy8tZuL6C2voQ+bnduNAnldH5PWKXVKor4d7PwqG9cO1z0G9UbN4nUdUdhtVPu+arrUsgNQvG\nXQbF17lneRjTiVkiCRPviSTc/sN1vLxmB/9YsY03PqigPqTk53bj7BF9OWdkf6YU9SItpZ07x/ds\ngvvPg1A9XPs89B7WvvtPRHs2uc7zpQ/Bod3uUbOTr3dJJCMn6OiM6RCWSMIkUiIJt/dgLS+t3sFL\na3bwVmkFh+tCZKencMaJfThnZD/OPKEvOZmp7fNmFR/AX86DlAy4egHkfaZ99ptIQiH3bI/F98KH\nL7lLd0+6wHWeF55uneemy7FEEiZRE0m4Q7UN/Kt0Fy+v2cE/1+1g14FakgTGFuQyfXhvThvehwmD\nc9t2n8q2FfDQF9wP6JVPuuFUuoLqSnfRweL7YO9m6N7PdZxPusYu3TVdmiWSMJ0hkYQLhZT3t+zl\n9fU7ebN0F8u37CWkkJWWzNSheZw2vDdTh+ZxYr9sko71KrCKD+ChL0LNPpj9KBSdHpuDCJqq6/NY\nfC+segoaamDIab7z/POQ3E5nesYkMEskYTpbImmq6mAd72zYxZsfuunj3e553T0yUigu7MXkwl5M\nLuzJmIIc0lOieAhS1VaXTHZ/BDNvh8lf7zzNOrUH3VDti++FbcsgrTuMm+06z23YEmOOYokkTGdP\nJE1t2X2Q9zbuZvGm3by3aTcbKqoBSE9JYtygXCYMymVMQQ5j83MZ1Ktb5CvCDu2Fp653fQXjr4AL\nfgOpCfIwr0i2LXcd5yvnweEq6DPCnX2Mmw3pcTIWmjFxxhJJmK6WSJqqPFDD4k17WLxpNyWbdrN2\n235qG0IA5GamMiY/h7EFOYzJz2XEgGwG9cx0TWKhELx+O7z+K8gbDl+8Bwpa/U7Fj0N7YOV8N+ru\n9hWQnA4jLoTir8GQaZ3nLMuYGLFEEqarJ5KmautDfLBjPyvKqlhRtpcVZVWs37GfhpD7LnRLTeaE\nft05oV82J/bP5mRdwcjFPyLpwDbklJvcsCrp3QM+imbU18KGhe6ZH2ufcX0f/cfAhKvc3fuZcfwA\nMmPijCWSMJZIWne4roG12/bxwY79rN9+gPU79rF++wF2HagBIJuD/CzjUS7lVaqSe7Go8EYOjLyM\nwj49KMzLomdmauzvxG9OqAE2/8udfaxd4M5EMnLdw6ImfrXrXH1mTDuzRBLGEsnxqzxQw/od+1m/\nfT8bKqpJLi/h0l13Mya0no9CA7i34Xyeajid9IxMBvXKZGBuNwbmZLjX3G4MzHXzfbMz2nccsdqD\nsOlN+OAFWPccHNju7jo/6QIYfSl85rM2bIkxbWSJJIwlknamSt2qp2l44w4yKlZyKLUXS3LP4ZXk\nM3jnYAHl+w6z/3D9UZskJwl9s9Pp3T2dPtnp9O6eFjZ/dHl2Ruqnk04oBDvXwOa33U2DG193412l\ndXdJY/QlMPxz9pxzY9pRXCQSEZkJ/A5IBu5V1dubrE8HHgQmAZXAZaq6ya+7FbgOaAC+raovRrPP\nSCyRxIgqbHwD3pvjhlEP1bnncHzmsxwsOJ3y7qPZUpdNedVhyvceYntVDbsOfDJVHqilPvTp75+I\nMiy9ignpWxmdtIXR+gEn1q4mK7QfgKqMArb3P4PKgWdxeOBUunXLJCs9mcy0FLqnp5CZnkxWWkrH\njaRsTCcVeCIRkWTgA+AcoAxYDFyuqmvC6nwTGKuq3xCR2cAXVfUyERkJPAZMAQYCrwAn+M1a3Gck\nlkg6wMHd7smA61+ATW9BnbvkmMze0HcE9MiHHgOgW083DEtKOqGGBg4f3M/BA1XU7auAfWWkHSgn\n61A5GQ37j+x6a3I+y5JGsqjhJF6vGc7mht5RhZSRmkRWmkssGSnJpKcmkZ6STHpKkp8ay9x8Rvj6\n1CRSk5NISU4iJUnclCykJPnlxvLGsmRfJ3ze1xGBJBE/gfjXxjJJ4si6JIlc35ggRJtIYvlEpSlA\nqapu8AHNBS4Gwn/0LwZ+5ufnA38U97/mYmCuqtYAG0Wk1O+PKPZpgpDZy11WW/w1d+XU1iXu3o0d\nK93d8pv/Bfu3uYEhvSQg00+k50DuIBhQCDmnueTTfwz0HUl+Rg/ygQtww+8frG1g3+E6qmsaOFhb\nT3VNA9U19VTX1nOw1s/XNFBdW091jSurqW+gpi5ETX2ImvoGDtTU++UGXxaips7NRzpLCtpRiUeO\nTjz4PNOYbhoTT3j++dS6I8tH15BP7atxubn1Rye5I+uPcbvj1a4ptp121l4xtddn9Oy3T4vuRuQ2\niGUiyQe2hC2XASc3V0dV60WkCsjz5e822Tbfz7e2TwBE5AbgBoDBgwcf3xGY45OSBkNOcVO4UAjq\nDkJ9jbssF3GXEadmQlJ0X3QRISs9hawYPlWyviFEbUOIWp9U6huU+lDok9cjZUp9Q6Q6br4hpNQ1\nKCFVVJWQQsi/qiqh0CdlGrau2frapH5IafAtCk0bFsJbGvRIWeOyNlk+ej1N10e5XeN6PrVem3mf\ntmnPdN9eLTPtFlM7Hpy0b7qNKJaJJFL0TT+e5uo0Vx5pRMKIH7mqzgHmgGvaaj5M02GSklziiNd7\nULwU36SVaRd9GROVdn6wxVHKgEFhywVAeXN1RCQFyAF2t7BtNPs0xhjTgWKZSBYDw0WkSETSgNnA\ngiZ1FgBX+/lZwKvqzjEXALNFJF1EioDhwHtR7tMYY0wHilnTlu/zuAl4EXep7v2qulpEbgNKVHUB\ncB/wkO9M341LDPh683Cd6PXAt1S1ASDSPmN1DMYYY1pnNyQaY4yJKNrLf2PZtGWMMaYLsERijDGm\nTSyRGGOMaRNLJMYYY9qkS3S2i0gFsPk4N+8N7GrHcGIpkWIFizeWEilWSKx4EylWaFu8Q1S1T2uV\nukQiaQsRKYnmqoV4kEixgsUbS4kUKyRWvIkUK3RMvNa0ZYwxpk0skRhjjGkTSyStmxN0AMcgkWIF\nizeWEilWSKx4EylW6IB4rY/EGGNMm9gZiTHGmDaxRGKMMaZNLJE0Q0Rmish6ESkVkVuCjgdARO4X\nkZ0isiqsrJeIvCwiH/rXnr5cROT3Pv4VIjKxg2MdJCILRWStiKwWke/EebwZIvKeiCz38f7clxeJ\nyCIf7+P+8QX4Rxw87uNdJCKFHRmvjyFZRN4XkX8kQKybRGSliCwTkRJfFq/fhVwRmS8i6/z395Q4\njvVE/5k2TvtE5OYOj1f9Yz1t+mTCDVH/ETAUSAOWAyPjIK7pwERgVVjZ/wNu8fO3AL/y8+cDz+Oe\nNjkVWNTBsQ4AJvr5bOADYGQcxytAdz+fCizyccwDZvvye4Ab/fw3gXv8/Gzg8QC+D/8BPAr8wy/H\nc6ybgN5NyuL1u/AA8HU/nwbkxmusTeJOBrYDQzo63kAOON4n4BTgxbDlW4Fbg47Lx1LYJJGsBwb4\n+QHAej//v8DlkeoFFPffgXMSIV4gE1gKnIy7Izil6fcC90ycU/x8iq8nHRhjAfBP4LPAP/wPQ1zG\n6t83UiKJu+8C0APY2PTzicdYI8R+LvCvIOK1pq3I8oEtYctlviwe9VPVbQD+ta8vj5tj8E0pE3B/\n5cdtvL6paBmwE3gZd1a6V1XrI8R0JF6/vgrI68Bw7wR+AIT8ch7xGyuAAi+JyBIRucGXxeN3YShQ\nAfzFNxveKyJZcRprU7OBx/x8h8ZriSQyiVCWaNdJx8UxiEh34EngZlXd11LVCGUdGq+qNqjqeNxf\n+1OAES3EFFi8InIhsFNVl4QXtxBP4J8tME1VJwLnAd8Skekt1A0y3hRc8/GfVHUCUI1rGmpOPHy2\n+P6wi4AnWqsaoazN8VoiiawMGBS2XACUBxRLa3aIyAAA/7rTlwd+DCKSiksij6jqU744buNtpKp7\ngddwbci5ItL4SOrwmI7E69fn4B4X3RGmAReJyCZgLq556844jRUAVS33rzuBp3GJOh6/C2VAmaou\n8svzcYklHmMNdx6wVFV3+OUOjdcSSWSLgeH+Kpg03CnjgoBjas4C4Go/fzWuL6Kx/Cp/lcZUoKrx\nVLcjiIgA9wFrVfWOBIi3j4jk+vluwNnAWmAhMKuZeBuPYxbwqvpG51hT1VtVtUBVC3HfzVdV9Yp4\njBVARLJEJLtxHteWv4o4/C6o6nZgi4ic6ItmAGviMdYmLueTZq3GuDou3iA6hRJhwl3d8AGunfzH\nQcfjY3oM2AbU4f6yuA7X1v1P4EP/2svXFeAuH/9KoLiDYz0Nd8q8Aljmp/PjON6xwPs+3lXAT3z5\nUOA9oBTXbJDuyzP8cqlfPzSg78SZfHLVVlzG6uNa7qfVjf+f4vi7MB4o8d+FvwE94zVWH0MmUAnk\nhJV1aLw2RIoxxpg2saYtY4wxbWKJxBhjTJtYIjHGGNMmlkiMMca0iSUSY4wxbWKJxJg4JiJnih/d\n15h4ZYnEGGNMm1giMaYdiMiV4p5nskxE/tcPAHlARH4jIktF5J8i0sfXHS8i7/rnQTwd9qyIYSLy\nirhnoiwVkc/43XcPez7GI37UAGPihiUSY9pIREYAl+EGJhwPNABXAFm48Y8mAq8DP/WbPAj8UFXH\n4u4ubix/BLhLVccBp+JGMQA3cvLNuOe5DMWNtWVM3EhpvYoxphUzgEnAYn+y0A03SF4IeNzXeRh4\nSkRygFxVfd2XPwA84ceiylfVpwFU9TCA3997qlrml5fhnknzVuwPy5joWCIxpu0EeEBVbz2qUOS/\nm9RraTyilpqrasLmG7D/tybOWNOWMW33T2CWiPSFI88iH4L7/9U4Gu9XgLdUtQrYIyKn+/KvAq+r\ne1ZLmYh8we8jXUQyO/QojDlO9peNMW2kqmtE5L9wTwBMwo3O/C3cQ5FGicgS3FMJL/ObXA3c4xPF\nBuBaX/5V4H9F5Da/jy914GEYc9xs9F9jYkREDqhq96DjMCbWrGnLGGNMm9gZiTHGmDaxMxJjjDFt\nYonEGGNMm1giMcYY0yaWSIwxxrSJJRJjjDFt8v8BuH0QO9e/pa0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f427319fcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'][500:])\n",
    "pyplot.plot(history.history['val_loss'][500:])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Multiple Runs Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMs are stochastic, meaning that you will get a different diagnostic plot each run.\n",
    "\n",
    "It can be useful to repeat the diagnostic run multiple times (e.g. 5, 10, or 30). The train and validation traces from each run can then be plotted to give a more robust idea of the behavior of the model over time.\n",
    "\n",
    "The example below runs the same experiment a number of times before plotting the trace of train and validation loss for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1114 - val_loss: 0.6575\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1102 - val_loss: 0.6530\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.6486\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1076 - val_loss: 0.6442\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1063 - val_loss: 0.6398\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1051 - val_loss: 0.6354\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.6310\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.6266\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 744us/step - loss: 0.1014 - val_loss: 0.6223\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1002 - val_loss: 0.6180\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.6137\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.6094\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.6052\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.6009\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.5967\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0931 - val_loss: 0.5925\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0919 - val_loss: 0.5883\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.5842\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.5800\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.5759\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.5718\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0863 - val_loss: 0.5677\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.5637\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.5596\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.5556\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.5516\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.5476\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.5436\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.5397\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.5357\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0768 - val_loss: 0.5318\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0758 - val_loss: 0.5279\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0748 - val_loss: 0.5240\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0738 - val_loss: 0.5202\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0728 - val_loss: 0.5163\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0719 - val_loss: 0.5125\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - val_loss: 0.5087\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.5048\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.5011\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - val_loss: 0.4973\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0671 - val_loss: 0.4935\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - val_loss: 0.4898\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - val_loss: 0.4861\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0644 - val_loss: 0.4823\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - val_loss: 0.4787\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - val_loss: 0.4750\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.4713\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.4677\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - val_loss: 0.4640\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0591 - val_loss: 0.4604\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.4568\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.4532\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.4496\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.4460\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.4425\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.4390\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.4354\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.4319\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.4284\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0510 - val_loss: 0.4250\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0502 - val_loss: 0.4215\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0494 - val_loss: 0.4181\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.4146\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 819us/step - loss: 0.0479 - val_loss: 0.4112\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.4078\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.4044\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.4011\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.3977\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.3944\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0437 - val_loss: 0.3910\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.3877\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0423 - val_loss: 0.3844\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0416 - val_loss: 0.3812\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0410 - val_loss: 0.3779\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.3747\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.3714\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.3682\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.3650\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.3619\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.3587\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.3556\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.3524\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.3493\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.3462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0343 - val_loss: 0.3432\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.3401\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.3371\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.3341\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0321 - val_loss: 0.3311\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.3281\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.3251\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.3222\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.3193\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.3163\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.3135\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.3106\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.3078\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.3049\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0272 - val_loss: 0.3021\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.2994\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.2966\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.2938\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.2911\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.2884\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.2858\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.2831\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.2805\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.2779\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.2753\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.2727\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.2702\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.2676\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.2651\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.2627\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0211 - val_loss: 0.2602\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.2578\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.2554\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.2530\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.2506\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.2483\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.2460\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.2437\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.2415\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.2392\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.2370\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.2348\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.2327\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.2305\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.2284\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.2263\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.2242\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.2222\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.2202\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.2182\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.2162\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.2143\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.2124\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.2105\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.2086\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.2068\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.2050\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.2032\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.2014\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.1997\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.1980\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1963\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1946\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.0140 - val_loss: 0.1930\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1914\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1898\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1882\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1866\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1851\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.1836\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1822\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1807\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1793\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1779\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.1765\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1751\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1738\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.0126 - val_loss: 0.1725\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.1712\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1699\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1687\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1675\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1651\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 794us/step - loss: 0.0121 - val_loss: 0.1639\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1628\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1617\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1606\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1595\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.1584\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.1574\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.1564\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1554\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.1544\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1534\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1525\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.1516\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1507\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1498\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1489\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1480\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 833us/step - loss: 0.0113 - val_loss: 0.1472\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1463\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1455\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1447\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1439\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 780us/step - loss: 0.0111 - val_loss: 0.1432\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1424\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1417\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1409\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1402\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1395\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1388\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1382\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1375\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1368\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1362\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 914us/step - loss: 0.0108 - val_loss: 0.1356\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1349\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.1343\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.1337\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1331\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.1326\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1320\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.1314\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.1309\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1303\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1298\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1293\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1287\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1282\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.1277\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1272\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1267\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 770us/step - loss: 0.0103 - val_loss: 0.1262\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1258\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 794us/step - loss: 0.0103 - val_loss: 0.1253\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1248\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1244\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1239\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1235\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1230\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.1226\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.1221\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.1217\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.1213\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1209\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1204\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1200\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1196\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1192\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1188\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.1184\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1180\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1176\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1172\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.1168\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1164\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1160\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1157\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1153\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.1149\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.1145\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.1141\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1138\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.1134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.1130\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.1127\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1123\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1119\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1116\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1112\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.1108\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1105\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.1101\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.1098\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.1094\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.1090\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.1087\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.1083\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.1080\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.1076\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.1073\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.1069\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.1066\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1062\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.1059\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.1055\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.1052\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.1048\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.1045\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.1041\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.1038\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.1034\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.1031\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.1027\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.1024\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1020\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.1017\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.1013\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.1010\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.1006\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.1003\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0999\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0996\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0993\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0989\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0986\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0982\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0979\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0975\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0972\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0968\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0965\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0962\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0958\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1128 - val_loss: 0.6725\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 887us/step - loss: 0.1114 - val_loss: 0.6676\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1101 - val_loss: 0.6627\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1087 - val_loss: 0.6578\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1074 - val_loss: 0.6530\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1060 - val_loss: 0.6482\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1047 - val_loss: 0.6434\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.6386\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1021 - val_loss: 0.6339\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1008 - val_loss: 0.6292\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 0.6245\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.6199\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 0.6153\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.6108\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.6063\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0934 - val_loss: 0.6018\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.5973\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0910 - val_loss: 0.5929\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0898 - val_loss: 0.5885\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.5842\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0875 - val_loss: 0.5799\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.5756\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.5713\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.5671\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.5630\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0820 - val_loss: 0.5588\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.5547\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0799 - val_loss: 0.5506\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.5466\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.5426\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.5386\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.5347\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.5308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.5269\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.5230\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0718 - val_loss: 0.5192\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - val_loss: 0.5154\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.5116\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.5079\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.5042\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - val_loss: 0.5005\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0663 - val_loss: 0.4969\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - val_loss: 0.4932\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.4896\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.4861\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - val_loss: 0.4825\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.4790\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0611 - val_loss: 0.4755\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.4720\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.4686\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.4651\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.4617\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.4583\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.4550\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.4516\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.4483\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0539 - val_loss: 0.4450\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0531 - val_loss: 0.4417\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.4385\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.4352\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.4320\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.4288\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.4256\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0488 - val_loss: 0.4224\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0481 - val_loss: 0.4193\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.4161\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.4130\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.4099\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0454 - val_loss: 0.4069\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0447 - val_loss: 0.4038\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0441 - val_loss: 0.4008\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.3977\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.3947\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0422 - val_loss: 0.3917\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.3888\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.3858\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.3829\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.3799\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0392 - val_loss: 0.3770\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0386 - val_loss: 0.3741\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.3713\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.3684\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - val_loss: 0.3656\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.3627\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0358 - val_loss: 0.3599\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.3571\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.3543\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.3516\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.3488\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.3461\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.3434\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - val_loss: 0.3407\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.3380\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.3354\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.3327\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0303 - val_loss: 0.3301\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0299 - val_loss: 0.3275\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.3249\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0290 - val_loss: 0.3223\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.3197\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.3172\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.3147\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.3122\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.3097\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.3072\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.3047\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.3023\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.2999\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.2975\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0246 - val_loss: 0.2951\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.2927\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.2904\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.2880\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.2857\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0229 - val_loss: 0.2834\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.2811\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.2789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.2767\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.2744\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.2722\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.2701\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.2679\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.2658\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.2636\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.2615\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.2595\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.2574\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.2554\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.2533\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.2513\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.2493\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.2474\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.2454\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.2435\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.2416\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.2397\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.2379\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.2360\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.2342\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.2324\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.2306\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.2289\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.2271\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.2254\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.2237\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.2221\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.2204\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.2188\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.2171\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.2155\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.2140\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.2124\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.2109\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.2094\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.0146 - val_loss: 0.2079\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.2064\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.2049\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.2035\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.2021\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.2007\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1993\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1980\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.1966\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1953\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1940\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1927\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1915\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.1902\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.1890\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.1878\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1866\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1854\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.1843\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.1831\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1820\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.1809\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1798\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.1787\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1777\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1766\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.1756\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.1746\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.1736\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.1727\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1717\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1708\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1698\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.1689\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.1680\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.1671\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.1663\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.1654\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.1646\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.1637\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1629\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1621\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1613\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.1605\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.1598\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.1590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1583\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1575\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.1568\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.1561\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.1554\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.1547\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1540\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1533\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.1527\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.1520\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.1514\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1507\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1501\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1495\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.1489\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.1483\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.1477\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1471\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1465\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.1460\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.1454\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1448\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1443\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1437\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.1432\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1427\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.1422\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.1416\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1411\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.1406\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.1401\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.1396\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1391\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.1386\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.1381\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.1377\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1372\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1367\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.1362\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1358\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.1353\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.1349\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1344\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.1339\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.1335\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.1331\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.1326\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.1322\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.1317\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1313\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.1309\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1304\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.1300\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1296\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1292\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.1287\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.1283\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.1279\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1275\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.1271\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.1266\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1262\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.1258\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.1254\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.1250\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.1246\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.1242\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1238\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1234\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1230\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1226\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.1222\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1218\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.1214\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.1210\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.1206\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.1202\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.1198\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.1194\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.1190\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1186\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.1182\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1174\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1170\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.1166\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.1162\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.1158\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.1154\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.1150\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.1146\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.1142\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.1138\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.1134\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.1130\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.1126\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.1122\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.1118\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.1114\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.1110\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.1146 - val_loss: 0.6928\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1131 - val_loss: 0.6877\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1116 - val_loss: 0.6827\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1101 - val_loss: 0.6776\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1087 - val_loss: 0.6726\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1073 - val_loss: 0.6677\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1058 - val_loss: 0.6627\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1044 - val_loss: 0.6578\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.6529\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1017 - val_loss: 0.6480\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1003 - val_loss: 0.6432\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0989 - val_loss: 0.6384\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0976 - val_loss: 0.6336\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0963 - val_loss: 0.6288\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0950 - val_loss: 0.6241\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0936 - val_loss: 0.6194\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0924 - val_loss: 0.6148\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.6101\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0898 - val_loss: 0.6055\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0886 - val_loss: 0.6010\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0873 - val_loss: 0.5964\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0861 - val_loss: 0.5919\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0849 - val_loss: 0.5874\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0837 - val_loss: 0.5829\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0825 - val_loss: 0.5785\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.5741\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0802 - val_loss: 0.5697\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.5654\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.5610\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0768 - val_loss: 0.5567\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0756 - val_loss: 0.5525\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.5482\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0735 - val_loss: 0.5440\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0724 - val_loss: 0.5398\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - val_loss: 0.5356\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.5315\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.5273\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.5232\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - val_loss: 0.5192\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.5151\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.5111\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.5071\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.5031\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - val_loss: 0.4991\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - val_loss: 0.4952\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.4912\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.4874\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0585 - val_loss: 0.4835\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.4796\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.4758\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.4720\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.4682\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0540 - val_loss: 0.4644\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.4607\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.4569\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.4532\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.4495\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0499 - val_loss: 0.4459\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.4422\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.4386\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0475 - val_loss: 0.4350\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0467 - val_loss: 0.4314\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.4278\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.4243\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.4207\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.4172\n",
      "Epoch 67/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0430 - val_loss: 0.4137\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.4103\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0416 - val_loss: 0.4068\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.4034\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.4000\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.3966\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.3932\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.3899\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.3866\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0370 - val_loss: 0.3833\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.3800\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.3767\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.3735\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0346 - val_loss: 0.3703\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.3671\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - val_loss: 0.3639\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.3607\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.3576\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0318 - val_loss: 0.3545\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.3514\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0307 - val_loss: 0.3484\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.3453\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0297 - val_loss: 0.3423\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.3393\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.3363\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.3334\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.3305\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.3276\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.3247\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.3219\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.3190\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.3162\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0252 - val_loss: 0.3135\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.3107\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.3080\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.3053\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.3026\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.3000\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.2973\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0226 - val_loss: 0.2947\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.2922\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.2896\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.2871\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0213 - val_loss: 0.2846\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.2821\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.2797\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0205 - val_loss: 0.2773\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.2749\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.2726\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.2702\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.2679\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.2656\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.2634\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.2612\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.2590\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.2568\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.2547\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.2526\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.2505\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.2484\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.2464\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.2444\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.2424\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.2405\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.2385\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.2366\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.2348\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.2329\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.2311\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.2293\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.2276\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.2259\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.2241\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.2225\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.2208\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.2192\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.2176\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.2160\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.2145\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.2129\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.2114\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.2100\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.2085\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.2071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.2057\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.2043\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.2030\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.2016\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.2003\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1990\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1978\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.1965\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1953\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.1941\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1930\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1918\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.1907\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.1896\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1885\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1874\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.1864\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.1853\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.1843\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1833\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.1823\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.1814\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.1804\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1795\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.1786\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.1777\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1768\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.1760\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1751\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1743\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1735\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.1727\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1719\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.1711\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.1704\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.1696\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1689\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1682\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1675\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.1668\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.1661\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.1654\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.1647\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.1641\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1634\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.1628\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1622\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.1616\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.1610\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.1604\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.1598\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.1592\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.1586\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.1581\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.1575\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.1570\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.1564\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.1559\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.1553\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.1548\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.1543\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.1538\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.1533\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.1528\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.1523\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.1518\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.1513\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.1508\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1503\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.1499\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1494\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1489\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1485\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1480\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.1475\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.1471\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.1466\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1462\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.1457\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.1453\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.1448\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.1444\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.1440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.1435\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.1431\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.1427\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.1422\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.1418\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.1414\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.1410\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.1406\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.1401\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.1397\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.1393\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.1389\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.1385\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.1380\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.1376\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1372\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1368\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.1364\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.1360\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.1356\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.1352\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.1348\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.1343\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.1339\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.1335\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.1331\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1327\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.1323\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1319\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1315\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1311\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1307\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.1303\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.1299\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.1295\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1291\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.1287\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1283\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.1279\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.1275\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1271\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.1267\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.1263\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.1259\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1255\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.1250\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1246\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.1242\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.1238\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.1234\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.1230\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.1226\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.1222\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.1218\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.1214\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.1210\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.1206\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1202\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1198\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1194\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.1190\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.1186\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.1182\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.1178\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.1174\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1170\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.1166\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1208 - val_loss: 0.7326\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 809us/step - loss: 0.1192 - val_loss: 0.7268\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1176 - val_loss: 0.7211\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1160 - val_loss: 0.7153\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.7096\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1128 - val_loss: 0.7039\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1113 - val_loss: 0.6983\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1097 - val_loss: 0.6926\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1082 - val_loss: 0.6870\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1067 - val_loss: 0.6814\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1052 - val_loss: 0.6759\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1037 - val_loss: 0.6704\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.6649\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1007 - val_loss: 0.6594\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0993 - val_loss: 0.6540\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.6486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0964 - val_loss: 0.6432\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0950 - val_loss: 0.6378\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0936 - val_loss: 0.6325\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0922 - val_loss: 0.6272\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.6220\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0895 - val_loss: 0.6167\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0881 - val_loss: 0.6115\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0868 - val_loss: 0.6064\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0855 - val_loss: 0.6012\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.5961\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.5910\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0816 - val_loss: 0.5860\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.5810\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0791 - val_loss: 0.5760\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.5711\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.5661\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0755 - val_loss: 0.5613\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.5564\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.5516\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0720 - val_loss: 0.5468\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - val_loss: 0.5420\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.5373\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - val_loss: 0.5326\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.5279\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.5233\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - val_loss: 0.5187\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0643 - val_loss: 0.5141\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0633 - val_loss: 0.5096\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0622 - val_loss: 0.5051\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0612 - val_loss: 0.5006\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.4961\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0592 - val_loss: 0.4917\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0582 - val_loss: 0.4873\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0573 - val_loss: 0.4830\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.4786\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.4743\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.4701\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.4658\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0526 - val_loss: 0.4616\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.4574\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0509 - val_loss: 0.4533\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0500 - val_loss: 0.4492\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0492 - val_loss: 0.4451\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0483 - val_loss: 0.4410\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0475 - val_loss: 0.4370\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0467 - val_loss: 0.4330\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.4290\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.4251\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.4212\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.4173\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.4134\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.4096\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.4058\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.4020\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.3983\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.3946\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.3909\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.3872\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0372 - val_loss: 0.3836\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.3800\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.3765\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.3729\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0347 - val_loss: 0.3694\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0341 - val_loss: 0.3659\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0335 - val_loss: 0.3625\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0329 - val_loss: 0.3591\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0324 - val_loss: 0.3557\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0318 - val_loss: 0.3523\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0313 - val_loss: 0.3490\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.3457\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0302 - val_loss: 0.3425\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.3392\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 847us/step - loss: 0.0292 - val_loss: 0.3360\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.3328\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.3297\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.3266\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.3235\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.3204\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.3174\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.3144\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 974us/step - loss: 0.0256 - val_loss: 0.3114\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.3085\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.3056\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0243 - val_loss: 0.3027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0240 - val_loss: 0.2999\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.2971\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.2943\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.2915\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.2888\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.2861\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.2835\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.2808\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.2782\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.2757\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.2731\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.2706\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.2681\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0198 - val_loss: 0.2657\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.2633\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.2609\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.2585\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.2562\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.2539\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.2517\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.2494\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.2472\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.2451\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.2429\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.2408\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.2387\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.2367\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.2347\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.2327\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.2307\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.2288\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.2269\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.2250\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.2231\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.2213\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.2195\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0154 - val_loss: 0.2178\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.2160\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.2143\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.2126\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.2110\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.2094\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.2078\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.2062\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.2046\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.2031\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.2016\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.2002\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1987\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.1973\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1959\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1945\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.1932\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.1918\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.1905\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1893\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.1880\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.1868\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.1856\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.1844\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.1832\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.1821\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.1809\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.1798\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.1787\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.1777\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.1766\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.1756\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.1746\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1736\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.1726\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1716\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1707\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.1698\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.1688\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1680\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.1671\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.1662\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.1654\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.1645\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.1637\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1629\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1613\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.1606\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.1598\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.1591\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.1583\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.1576\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.1569\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.1562\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.1555\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.1549\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.1542\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.1535\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.1529\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.1523\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.1516\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.1510\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1504\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.1498\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.1492\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.1486\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.1480\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1475\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.1469\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.1463\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.1458\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1452\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.1447\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.1442\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.1436\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.1431\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.1426\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1421\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1416\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.1411\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.1406\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.1401\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.1396\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1391\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1386\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1382\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.1377\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1372\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1367\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1363\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.1358\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.1354\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.1349\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.1344\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.1340\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.1335\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.1331\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.1327\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.1322\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1318\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.1313\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1309\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1305\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.1300\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.1296\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.1292\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.1287\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.1283\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.1279\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.1275\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.1270\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1266\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.1262\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.1258\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1254\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1249\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.1245\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1241\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.1237\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.1233\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.1228\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.1224\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 930us/step - loss: 0.0100 - val_loss: 0.1220\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1216\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1212\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.1208\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.1204\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.1200\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.1191\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.1187\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1183\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1179\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.1175\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1171\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1167\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.1163\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.1159\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.1155\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1151\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.1146\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1142\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.1138\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.1134\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1130\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1126\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.1122\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1118\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1114\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1110\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1106\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.1102\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1098\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.1094\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1090\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1086\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1082\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1078\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.1074\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.1070\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.1066\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.1062\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1058\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0936 - val_loss: 0.5319\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.5271\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.5223\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.5175\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.5127\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.5079\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.5032\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.4985\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.4938\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.4891\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.0802 - val_loss: 0.4845\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 811us/step - loss: 0.0790 - val_loss: 0.4799\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0777 - val_loss: 0.4753\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0765 - val_loss: 0.4707\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0752 - val_loss: 0.4662\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0740 - val_loss: 0.4616\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.4572\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0716 - val_loss: 0.4527\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.4483\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0693 - val_loss: 0.4438\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - val_loss: 0.4395\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - val_loss: 0.4351\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.4308\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0647 - val_loss: 0.4265\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - val_loss: 0.4222\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0625 - val_loss: 0.4180\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.4137\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0603 - val_loss: 0.4095\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.4054\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.4013\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.3972\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.3931\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0552 - val_loss: 0.3890\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.3850\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.3810\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0522 - val_loss: 0.3771\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0513 - val_loss: 0.3731\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.3692\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.3653\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.3615\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.3577\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 765us/step - loss: 0.0467 - val_loss: 0.3539\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.3501\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0450 - val_loss: 0.3464\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.3427\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.3390\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 807us/step - loss: 0.0424 - val_loss: 0.3354\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.3317\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 788us/step - loss: 0.0408 - val_loss: 0.3281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.3246\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.3210\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.3175\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0377 - val_loss: 0.3141\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.3106\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.3072\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 780us/step - loss: 0.0355 - val_loss: 0.3038\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.3004\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.2971\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.2938\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0327 - val_loss: 0.2905\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.2872\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.2840\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.2808\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.2777\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.2745\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.2714\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.2683\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.2653\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.2623\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.2593\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.2563\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 881us/step - loss: 0.0256 - val_loss: 0.2534\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.2505\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.2476\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.2447\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.2419\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.2391\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.2364\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.0221 - val_loss: 0.2336\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.2309\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.2283\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.2256\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.2230\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.2204\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.2179\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.2154\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.2129\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.2104\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.2080\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.2056\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.2032\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.2009\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.1985\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.1963\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.1940\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.1918\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.1896\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.1874\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.1853\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.1832\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.1811\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1791\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.1770\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1751\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1731\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.1712\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.1693\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1674\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1656\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1637\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1620\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1602\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1585\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.1568\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.1551\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1534\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 778us/step - loss: 0.0112 - val_loss: 0.1518\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1502\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1487\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.1471\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1456\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.1441\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1427\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1412\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1398\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1385\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1371\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1358\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1345\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1332\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.1319\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.1307\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.1283\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1271\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1260\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 778us/step - loss: 0.0091 - val_loss: 0.1248\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.1238\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.1227\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1216\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1206\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1196\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.1186\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.1176\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1166\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.1157\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.1148\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.1139\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.1130\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1122\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.1113\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1105\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.1097\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.1089\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1081\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.1074\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.1066\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.1059\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.1052\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.1045\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.1038\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.1031\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.1025\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.1018\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.1012\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.1006\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 813us/step - loss: 0.0078 - val_loss: 0.1000\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0994\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0988\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0982\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0976\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0971\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0966\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0960\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0955\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0950\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0945\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0940\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0935\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0930\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0926\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0921\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0917\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0912\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0908\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0903\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0899\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0895\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0891\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0887\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0883\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0879\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0875\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0871\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.0072 - val_loss: 0.0868\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0864\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0860\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0856\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0853\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0849\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0846\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0842\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0839\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0835\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0832\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0829\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0825\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0822\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0819\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0816\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 772us/step - loss: 0.0068 - val_loss: 0.0812\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0809\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0806\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0803\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0800\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0794\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0791\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0787\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0784\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0781\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0778\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0775\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0772\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0769\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0766\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0764\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0761\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0758\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0755\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0752\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0749\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0746\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0743\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0740\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0737\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0735\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0732\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0729\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 760us/step - loss: 0.0063 - val_loss: 0.0726\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0723\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0720\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0718\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0715\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0712\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0709\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0706\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0703\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0701\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0698\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0695\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0692\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0689\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0687\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0684\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0681\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0678\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0675\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0673\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0670\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0667\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0664\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0661\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0659\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0656\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0653\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0650\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0648\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0645\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0642\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0639\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0637\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0634\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0631\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0628\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0625\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0623\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0620\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0617\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0614\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0612\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0609\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0606\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0603\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0601\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0598\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0595\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0593\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0590\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0587\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0584\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0582\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 775us/step - loss: 0.0052 - val_loss: 0.0579\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0576\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0573\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0571\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0568\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0565\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0560\n"
     ]
    }
   ],
   "source": [
    "# collect data across multiple repeats\n",
    "train = DataFrame()\n",
    "val = DataFrame()\n",
    "for i in range(5):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(10, input_shape=(1,1)))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\tX,y = get_train()\n",
    "\tvalX, valY = get_val()\n",
    "\t# fit model\n",
    "\thistory = model.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)\n",
    "\t# story history\n",
    "\ttrain[str(i)] = history.history['loss']\n",
    "\tval[str(i)] = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the resulting plot, we can see that the general trend of underfitting holds across 5 runs and is a stronger case for perhaps increasing the number of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWYIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4272fe00f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss across multiple runs\n",
    "pyplot.plot(train, color='blue', label='train')\n",
    "pyplot.plot(val, color='orange', label='validation')\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reasons for underfitting and how to solve it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Not enough number of iteration (epoch) :arrow_right: add number of epoch\n",
    "\n",
    "+ Model is not complex enough :arrow_right: add number of hidden neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reasons for overfitting and how to solve it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Too many epochs :arrow_right: choose the best early stopping point\n",
    "  \n",
    "+ Model is too complex :arrow_right: reduce complexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
