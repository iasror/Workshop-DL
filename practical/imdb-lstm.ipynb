{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Networks (LSTM) for Text Classification : IMDB Movie sentiment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "\n",
    "Notes\n",
    "\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         640000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 771,713\n",
      "Trainable params: 771,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/25\n",
      "25000/25000 [==============================] - 560s 22ms/step - loss: 0.5017 - acc: 0.7536 - val_loss: 0.4346 - val_acc: 0.8036\n",
      "Epoch 2/25\n",
      "25000/25000 [==============================] - 995s 40ms/step - loss: 0.3517 - acc: 0.8518 - val_loss: 0.3554 - val_acc: 0.8435\n",
      "Epoch 3/25\n",
      "25000/25000 [==============================] - 909s 36ms/step - loss: 0.3083 - acc: 0.8734 - val_loss: 0.3649 - val_acc: 0.8383\n",
      "Epoch 4/25\n",
      "25000/25000 [==============================] - 771s 31ms/step - loss: 0.2796 - acc: 0.8854 - val_loss: 0.3591 - val_acc: 0.8474\n",
      "Epoch 5/25\n",
      "25000/25000 [==============================] - 569s 23ms/step - loss: 0.2540 - acc: 0.8973 - val_loss: 0.3741 - val_acc: 0.8473\n",
      "Epoch 6/25\n",
      "25000/25000 [==============================] - 556s 22ms/step - loss: 0.2217 - acc: 0.9112 - val_loss: 0.3981 - val_acc: 0.8414\n",
      "Epoch 7/25\n",
      "25000/25000 [==============================] - 501s 20ms/step - loss: 0.1998 - acc: 0.9209 - val_loss: 0.4380 - val_acc: 0.8432\n",
      "Epoch 8/25\n",
      "25000/25000 [==============================] - 504s 20ms/step - loss: 0.1794 - acc: 0.9297 - val_loss: 0.4488 - val_acc: 0.8412\n",
      "Epoch 9/25\n",
      "25000/25000 [==============================] - 339s 14ms/step - loss: 0.1537 - acc: 0.9429 - val_loss: 0.5028 - val_acc: 0.8400\n",
      "Epoch 10/25\n",
      "25000/25000 [==============================] - 249s 10ms/step - loss: 0.1430 - acc: 0.9474 - val_loss: 0.5407 - val_acc: 0.8379\n",
      "Epoch 11/25\n",
      "25000/25000 [==============================] - 247s 10ms/step - loss: 0.1297 - acc: 0.9540 - val_loss: 0.5404 - val_acc: 0.8340\n",
      "Epoch 12/25\n",
      "25000/25000 [==============================] - 248s 10ms/step - loss: 0.1218 - acc: 0.9549 - val_loss: 0.5418 - val_acc: 0.8368\n",
      "Epoch 13/25\n",
      "25000/25000 [==============================] - 247s 10ms/step - loss: 0.1023 - acc: 0.9628 - val_loss: 0.5939 - val_acc: 0.8328\n",
      "Epoch 14/25\n",
      "25000/25000 [==============================] - 247s 10ms/step - loss: 0.0984 - acc: 0.9654 - val_loss: 0.6227 - val_acc: 0.8352\n",
      "Epoch 15/25\n",
      "25000/25000 [==============================] - 248s 10ms/step - loss: 0.0806 - acc: 0.9724 - val_loss: 0.7227 - val_acc: 0.8278\n",
      "Epoch 16/25\n",
      "25000/25000 [==============================] - 439s 18ms/step - loss: 0.0772 - acc: 0.9747 - val_loss: 0.6531 - val_acc: 0.8298\n",
      "Epoch 17/25\n",
      "25000/25000 [==============================] - 576s 23ms/step - loss: 0.0629 - acc: 0.9794 - val_loss: 0.7134 - val_acc: 0.8334\n",
      "Epoch 18/25\n",
      "25000/25000 [==============================] - 567s 23ms/step - loss: 0.0584 - acc: 0.9810 - val_loss: 0.7974 - val_acc: 0.8270\n",
      "Epoch 19/25\n",
      "25000/25000 [==============================] - 345s 14ms/step - loss: 0.0522 - acc: 0.9823 - val_loss: 0.8603 - val_acc: 0.8330\n",
      "Epoch 20/25\n",
      "25000/25000 [==============================] - 306s 12ms/step - loss: 0.0475 - acc: 0.9845 - val_loss: 0.8296 - val_acc: 0.8262\n",
      "Epoch 21/25\n",
      "25000/25000 [==============================] - 313s 13ms/step - loss: 0.0545 - acc: 0.9821 - val_loss: 0.7646 - val_acc: 0.8284\n",
      "Epoch 22/25\n",
      "25000/25000 [==============================] - 305s 12ms/step - loss: 0.0441 - acc: 0.9855 - val_loss: 0.8757 - val_acc: 0.8274\n",
      "Epoch 23/25\n",
      "25000/25000 [==============================] - 294s 12ms/step - loss: 0.0434 - acc: 0.9860 - val_loss: 0.7875 - val_acc: 0.8252\n",
      "Epoch 24/25\n",
      "25000/25000 [==============================] - 310s 12ms/step - loss: 0.0296 - acc: 0.9907 - val_loss: 0.8945 - val_acc: 0.8261\n",
      "Epoch 25/25\n",
      "25000/25000 [==============================] - 360s 14ms/step - loss: 0.0314 - acc: 0.9911 - val_loss: 0.9206 - val_acc: 0.8271\n",
      "25000/25000 [==============================] - 103s 4ms/step\n",
      "Test score: 0.92063839519\n",
      "Test accuracy: 0.827119998455\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=25,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
